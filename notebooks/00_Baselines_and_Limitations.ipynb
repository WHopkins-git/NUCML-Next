{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Notebook 00: Baselines and Limitations\n\n## Understanding Why Classical ML Fails for Nuclear Data\n\n**Learning Objective:** Understand *why* classical machine learning fails for nuclear data evaluation using real experimental data.\n\n**Focus Isotopes:**\n- **U-235 Fission** (data-rich, well-understood): Critical for nuclear reactors\n- **Cl-35 (n,p)** (data-sparse, research interest): Important for astrophysics and medical applications\n\n### The Problem\n\nNuclear cross sections \u03c3(E) are smooth, continuous functions of energy. They exhibit:\n- **Resonance peaks**: Sharp but smooth features (especially visible in U-235)\n- **Threshold behavior**: \u03c3(E) = 0 for E < E_threshold, then rises smoothly\n- **Physical constraints**: Conservation laws, unitarity, causality\n\n### Why This Matters\n\nA reactor calculation uses millions of cross-section evaluations. If predictions are:\n- **Jagged** \u2192 Unphysical neutron transport\n- **Discontinuous** \u2192 Numerical instabilities\n- **Wrong at key energies** \u2192 Incorrect k_eff (criticality)\n\nThis is the **Validation Paradox**: Low MSE \u2260 Safe Reactor!\n\n**Additional Challenge:** How do models perform when data is sparse (like Cl-35)?\n\n---\n\n## Part 1: The Naive Approach\n\nLet's examine why tree-based models struggle with real nuclear cross-section data from IAEA EXFOR."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "import sys\nsys.path.append('..')\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pathlib import Path\n\nfrom nucml_next.data import NucmlDataset\nfrom nucml_next.baselines import XGBoostEvaluator, DecisionTreeEvaluator\n\n# Set plotting style\nplt.style.use('seaborn-v0_8-darkgrid')\nsns.set_palette(\"husl\")\n%matplotlib inline\n\n# Verify EXFOR data exists\nexfor_path = Path('../data/exfor_processed.parquet')\nif not exfor_path.exists():\n    raise FileNotFoundError(\n        f\"EXFOR data not found at {exfor_path}\\n\"\n        \"Please run: python scripts/ingest_exfor.py --exfor-root <path> --output data/exfor_processed.parquet\"\n    )\n\nprint(\"\u2713 Imports successful\")\nprint(\"\u2713 EXFOR data found\")\nprint(\"Welcome to NUCML-Next: Understanding ML Limitations with Real Nuclear Data\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Step 1.1: Load Real EXFOR Data (Tabular View)\n\nWe'll train on the **full EXFOR database** (all isotopes), then evaluate on U-235 and Cl-35. This is the correct ML approach:\n- **Training**: Learn general nuclear physics patterns from ALL available data\n- **Evaluation**: Test predictions on specific target isotopes (U-235, Cl-35)\n\nThis demonstrates true transfer learning and generalization, not just memorization!"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# CRITICAL FIX: Use physics-aware DataSelection for scientifically defensible filtering\n# This demonstrates proper ML workflow with predicate pushdown for efficiency\n\nfrom nucml_next.data import DataSelection\n\n# Strategy: Train on neutron-induced reactions at reactor energies (scientifically defensible default)\n# This avoids training on:\n# - Bookkeeping codes (MT 0, 1, 9000+) which are arithmetic identities\n# - Non-reactor energies (too high/low for criticality calculations)\n# - Non-neutron projectiles (we're focused on reactor physics)\n\nprint(\"Creating physics-aware data selection...\")\nprint(\"=\" * 80)\n\n# Training selection: Reactor physics, neutrons, all physical reactions\ntraining_selection = DataSelection(\n    # ============================================================================\n    # PROJECTILE SELECTION\n    # ============================================================================\n    projectile='neutron',          # Options: 'neutron' | 'all'\n                                   # 'neutron' = Only neutron-induced reactions (reactor physics)\n                                   # 'all' = All projectiles (n, p, d, \u03b1, \u03b3, etc.)\n    \n    # ============================================================================\n    # ENERGY RANGE (eV)\n    # ============================================================================\n    energy_min=1e-5,               # Minimum energy in eV (1e-5 = 0.01 eV, thermal neutrons)\n    energy_max=2e7,                # Maximum energy in eV (2e7 = 20 MeV, reactor physics upper bound)\n                                   # Common ranges:\n                                   #   - Thermal: 1e-5 to 1 eV\n                                   #   - Resonance: 1 to 1e4 eV\n                                   #   - Fast: 1e4 to 2e7 eV (20 MeV)\n                                   #   - High energy: up to 1e9 eV (1 GeV)\n    \n    # ============================================================================\n    # REACTION (MT) MODE SELECTION\n    # ============================================================================\n    mt_mode='all_physical',        # Options:\n                                   # 'reactor_core'   \u2192 Essential for reactor modeling\n                                   #                    (MT 2, 4, 16, 18, 102, 103, 107)\n                                   #                    [elastic, inelastic, (n,2n), fission,\n                                   #                     capture, (n,p), (n,\u03b1)]\n                                   #\n                                   # 'threshold_only' \u2192 Reactions with energy thresholds\n                                   #                    (MT 16, 17, 103, 104, 105, 106, 107)\n                                   #                    [(n,2n), (n,3n), (n,p), (n,d), (n,t),\n                                   #                     (n,\u00b3He), (n,\u03b1)]\n                                   #\n                                   # 'fission_details'\u2192 Fission breakdown channels\n                                   #                    (MT 18, 19, 20, 21, 38)\n                                   #                    [total fission, 1st chance, 2nd chance,\n                                   #                     3rd chance, 4th chance]\n                                   #\n                                   # 'all_physical'   \u2192 All codes < 9000, excluding bookkeeping\n                                   #                    (Includes all real reactions, excludes\n                                   #                     derived/total cross-sections)\n                                   #\n                                   # 'custom'         \u2192 Use custom_mt_codes list (see below)\n    \n    custom_mt_codes=None,          # Used only when mt_mode='custom'\n                                   # Example: [2, 18, 102]  # Elastic, fission, capture\n                                   # Example: [16, 17, 18]  # (n,2n), (n,3n), fission\n                                   # Example: list(range(50, 92))  # MT 50-91 (inelastic levels)\n    \n    # ============================================================================\n    # EXCLUSION RULES\n    # ============================================================================\n    exclude_bookkeeping=True,      # Exclude MT 0, 1, and MT >= 9000\n                                   # MT 0 = Undefined\n                                   # MT 1 = Total cross-section (sum of others)\n                                   # MT >= 9000 = Lumped reaction covariances\n                                   # These are arithmetic identities, not physics!\n    \n    # ============================================================================\n    # DATA VALIDITY\n    # ============================================================================\n    drop_invalid=True,             # Drop NaN or non-positive cross-sections\n                                   # Essential for log-transform: log(\u03c3) requires \u03c3 > 0\n                                   # Prevents training instabilities\n    \n    # ============================================================================\n    # EVALUATION CONTROLS (Holdout for Extrapolation Testing)\n    # ============================================================================\n    holdout_isotopes=None          # List of (Z, A) tuples to exclude from training\n                                   # None = Use all data (default for training)\n                                   # Example: [(92, 235)]           # Hold out U-235 only\n                                   # Example: [(92, 235), (17, 35)] # Hold out U-235 and Cl-35\n                                   # Example: [(94, 239), (94, 240), (94, 241)]  # Pu isotopes\n                                   # Use this to measure TRUE extrapolation capability!\n)\n\nprint(\"Training Selection:\")\nprint(training_selection)\nprint()\n\n# Load FULL dataset for training with physics-aware filtering\n# CRITICAL: Predicate pushdown filters at PyArrow fragment level (90% I/O reduction!)\nprint(\"=\" * 80)\nprint(\"Loading training dataset with predicate pushdown...\")\nprint(\"=\" * 80)\ndataset_full = NucmlDataset(\n    data_path='../data/exfor_processed.parquet',\n    mode='tabular',\n    selection=training_selection  # Physics-aware selection with predicate pushdown\n)\n\n# Project to tabular format with NAIVE features\nprint(\"\\n\" + \"=\" * 80)\nprint(\"Projecting to tabular format (naive mode)...\")\nprint(\"=\" * 80)\ndf_naive = dataset_full.to_tabular(mode='naive')\n\nprint(f\"\\n\u2713 Full training dataset: {df_naive.shape}\")\nprint(f\"\\nFeatures (Naive Mode):\")\nprint(df_naive.columns.tolist())\n\n# Show isotope distribution in training data\nprint(\"\\n\ud83d\udcca Training Data Distribution (Top 10 Isotopes):\")\nisotope_counts = dataset_full.df.groupby(['Z', 'A']).size().sort_values(ascending=False).head(10)\nfor (z, a), count in isotope_counts.items():\n    # Simple element lookup (extend as needed)\n    element_map = {92: 'U', 17: 'Cl', 94: 'Pu', 26: 'Fe', 8: 'O', 1: 'H',\n                   82: 'Pb', 6: 'C', 13: 'Al', 7: 'N', 11: 'Na', 79: 'Au'}\n    elem = element_map.get(z, f'Z{z}')\n    print(f\"  {elem}-{a:3d}: {count:>8,} measurements\")\n\nprint(f\"\\n\u2713 Total isotopes: {dataset_full.df.groupby(['Z', 'A']).ngroups} unique Z/A combinations\")\nprint(f\"\u2713 Total reaction types: {dataset_full.df['MT'].nunique()} unique MT codes\")\nprint(f\"\u2713 Total measurements: {len(dataset_full.df):,}\")\n\n# Show MT distribution\nprint(\"\\n\ud83d\udcca Top 10 Reaction Types (MT codes):\")\nmt_counts = dataset_full.df['MT'].value_counts().head(10)\nmt_names = {18: 'Fission', 102: '(n,\u03b3) Capture', 103: '(n,p)', 2: 'Elastic',\n            16: '(n,2n)', 17: '(n,3n)', 4: 'Inelastic', 107: '(n,\u03b1)'}\nfor mt, count in mt_counts.items():\n    name = mt_names.get(mt, f'MT-{mt}')\n    print(f\"  MT {mt:3d} {name:15s}: {count:>8,} measurements\")\n\nprint(f\"\\n\u2713 Training on neutron-induced reactions allows transfer learning!\")\nprint(f\"\u2713 Predicate pushdown reduced load time by filtering at fragment level\")\n\n# Now load evaluation targets (U-235 and Cl-35) using legacy filters for specific selection\nprint(\"\\n\" + \"=\"*70)\nprint(\"Loading evaluation targets (U-235 and Cl-35) using legacy filters...\")\nprint(\"NOTE: For evaluation, we use legacy filters for precise isotope/MT selection\")\nprint(\"=\"*70)\ndataset_eval = NucmlDataset(\n    data_path='../data/exfor_processed.parquet',\n    mode='tabular',\n    filters={  # Legacy filters for backward compatibility\n        'Z': [92, 17],     # Uranium and Chlorine\n        'A': [235, 35],    # U-235 and Cl-35\n        'MT': [18, 102, 103]  # Fission, capture, (n,p) - for visualization\n    }\n)\n\nprint(f\"\u2713 Evaluation dataset: {len(dataset_eval.df)} measurements\")\nprint(\"\\n\ud83d\udcca Evaluation Isotopes:\")\nfor (z, a), group in dataset_eval.df.groupby(['Z', 'A']):\n    isotope = f\"{'U' if z==92 else 'Cl'}-{a}\"\n    print(f\"  {isotope:8s}: {len(group):>6,} measurements\")\nprint(\"=\"*70)\n\ndf_naive.head()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Notice:** The naive approach treats reactions as independent categories (MT_2, MT_18, etc.).\n",
        "\n",
        "**Problem:** This ignores physics! (n,2n) and (n,3n) are related - they differ by one neutron.\n",
        "\n",
        "But tree-based models don't know this. To them, MT=16 and MT=17 are just labels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 1.2: Train Decision Tree (The \"Villain\")\n",
        "\n",
        "We'll intentionally configure the tree to show the **staircase effect**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize Decision Tree with limited depth (exaggerates stairs)\n",
        "dt_model = DecisionTreeEvaluator(\n",
        "    max_depth=6,          # Shallow tree = coarse stairs\n",
        "    min_samples_leaf=20,  # Large leaves = big steps\n",
        ")\n",
        "\n",
        "# Train on naive features\n",
        "dt_metrics = dt_model.train(df_naive)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Decision Tree Performance:\")\n",
        "print(\"=\"*60)\n",
        "for key, value in dt_metrics.items():\n",
        "    print(f\"  {key:20s}: {value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Step 1.3: The Failure Mode - Visualize the Staircase Effect\n\nLet's predict cross sections for both isotopes and see what happens...\n\n**U-235**: Rich data \u2192 Can the model capture resonances?  \n**Cl-35**: Sparse data \u2192 Can the model interpolate gaps?"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ============================================================================\n# HELPER FUNCTIONS for Clean Cross-Section Plotting\n# ============================================================================\n\ndef _clean_xy(df, col_x='Energy', col_y='CrossSection', emin=None, emax=None):\n    \"\"\"\n    Clean and prepare data for log-log plotting.\n    \n    - Drops NaN values in Energy and CrossSection\n    - Removes non-positive Energy and CrossSection (required for log scale)\n    - Filters by energy range if specified\n    - Sorts by Energy to avoid line-crossing artifacts\n    \n    Args:\n        df: DataFrame with Energy and CrossSection columns\n        col_x: Name of energy column\n        col_y: Name of cross-section column\n        emin: Minimum energy (eV), optional\n        emax: Maximum energy (eV), optional\n    \n    Returns:\n        Cleaned DataFrame sorted by Energy\n    \"\"\"\n    df_clean = df.copy()\n    \n    # Drop NaN values\n    df_clean = df_clean.dropna(subset=[col_x, col_y])\n    \n    # Remove non-positive values (required for log scale)\n    df_clean = df_clean[(df_clean[col_x] > 0) & (df_clean[col_y] > 0)]\n    \n    # Apply energy range filter if specified\n    if emin is not None:\n        df_clean = df_clean[df_clean[col_x] >= emin]\n    if emax is not None:\n        df_clean = df_clean[df_clean[col_x] <= emax]\n    \n    # CRITICAL: Sort by Energy to avoid line-crossing artifacts\n    df_clean = df_clean.sort_values(by=col_x).reset_index(drop=True)\n    \n    return df_clean\n\n\ndef _clip_positive(arr, floor=1e-30):\n    \"\"\"\n    Clip array values to minimum positive floor.\n    \n    Prevents log(0) errors by ensuring all values are at least 'floor'.\n    Useful for prediction arrays that may contain zeros or negatives.\n    \n    Args:\n        arr: Numpy array or list\n        floor: Minimum positive value (default: 1e-30)\n    \n    Returns:\n        Numpy array with values >= floor\n    \"\"\"\n    arr = np.asarray(arr)\n    return np.clip(arr, floor, None)\n\n\n# ============================================================================\n# CREATE COMPARATIVE VISUALIZATION: U-235 (data-rich) vs Cl-35 (data-sparse)\n# ============================================================================\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 7))\n\n# ============================================================================\n# LEFT PANEL: U-235 Fission (Data-Rich, Resonance Region)\n# ============================================================================\n\nZ_u, A_u = 92, 235\nmt_u = 18  # Fission\nenergy_range_u = (1.0, 100.0)  # 1-100 eV (resonance region)\n\n# Extract and clean U-235 ground truth from evaluation dataset\nmask_u = (dataset_eval.df['Z'] == Z_u) & (dataset_eval.df['A'] == A_u) & (dataset_eval.df['MT'] == mt_u)\ndf_truth_u = dataset_eval.df[mask_u].copy()\ndf_truth_u = _clean_xy(df_truth_u, emin=energy_range_u[0], emax=energy_range_u[1])\n\nif len(df_truth_u) > 0:\n    # Get Decision Tree predictions (dense sampling to see staircase)\n    energies_dt_u, predictions_dt_u = dt_model.predict_resonance_region(\n        Z_u, A_u, mt_u, energy_range_u, num_points=500, mode='naive'\n    )\n    \n    # Clip predictions to avoid log(0) errors\n    predictions_dt_u = _clip_positive(predictions_dt_u, floor=1e-30)\n    \n    # Plot ground truth as SCATTER (blue) - avoids \"spaghetti\" lines\n    ax1.scatter(df_truth_u['Energy'], df_truth_u['CrossSection'], \n                s=30, c='tab:blue', marker='o', \n                label=f'Ground Truth ({len(df_truth_u)} EXFOR pts)', \n                alpha=0.6, zorder=2, edgecolors='none')\n    \n    # Plot Decision Tree prediction as LINE (red)\n    ax1.plot(energies_dt_u, predictions_dt_u, \n             'tab:red', linewidth=2.0, \n             label='Decision Tree (Staircase)', \n             alpha=0.8, zorder=1)\n    \n    # Configure axes: LOG-LOG\n    ax1.set_xscale('log')\n    ax1.set_yscale('log')\n    ax1.set_xlabel('Energy (eV)', fontsize=12, fontweight='bold')\n    ax1.set_ylabel('Cross Section (barns)', fontsize=12, fontweight='bold')\n    ax1.set_title('U-235 Fission (DATA-RICH): Staircase Effect\\n' + \n                  f'{len(df_truth_u)} EXFOR measurements in range\\n' +\n                  '(Model trained on full EXFOR database)',\n                  fontsize=13, fontweight='bold')\n    ax1.legend(fontsize=11, loc='best')\n    ax1.grid(True, alpha=0.3, which='both')  # Grid on both major and minor ticks\n    \n    # Annotate the problem - use safe indexing\n    if len(predictions_dt_u) > 250:\n        mid_idx = min(250, len(predictions_dt_u) - 1)\n        anno_x = energies_dt_u[mid_idx]\n        anno_y = predictions_dt_u[mid_idx]\n        ax1.annotate('Unphysical steps!\\n(Real resonances are smooth)',\n                     xy=(anno_x, anno_y), \n                     xytext=(anno_x * 2, anno_y * 3),\n                     arrowprops=dict(arrowstyle='->', color='tab:red', lw=2),\n                     fontsize=10, color='tab:red', fontweight='bold',\n                     bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7))\nelse:\n    ax1.text(0.5, 0.5, 'No U-235 fission data in range\\n(Check EXFOR ingestion)',\n             ha='center', va='center', transform=ax1.transAxes, fontsize=11)\n    ax1.set_title('U-235 Fission (No Data)', fontsize=13, fontweight='bold')\n    ax1.set_xscale('log')\n    ax1.set_yscale('log')\n    ax1.grid(True, alpha=0.3, which='both')\n\n\n# ============================================================================\n# RIGHT PANEL: Cl-35 (n,p) (Data-Sparse, Fast Neutron Region)\n# ============================================================================\n\nZ_cl, A_cl = 17, 35\nmt_cl = 103  # (n,p)\nenergy_range_cl = (1e6, 2e7)  # 1-20 MeV (fast neutron region)\n\n# Extract and clean Cl-35 ground truth from evaluation dataset\nmask_cl = (dataset_eval.df['Z'] == Z_cl) & (dataset_eval.df['A'] == A_cl) & (dataset_eval.df['MT'] == mt_cl)\ndf_truth_cl = dataset_eval.df[mask_cl].copy()\ndf_truth_cl = _clean_xy(df_truth_cl, emin=energy_range_cl[0], emax=energy_range_cl[1])\n\nif len(df_truth_cl) > 0:\n    # Get Decision Tree predictions\n    energies_dt_cl, predictions_dt_cl = dt_model.predict_resonance_region(\n        Z_cl, A_cl, mt_cl, energy_range_cl, num_points=500, mode='naive'\n    )\n    \n    # Clip predictions to avoid log(0) errors\n    predictions_dt_cl = _clip_positive(predictions_dt_cl, floor=1e-30)\n    \n    # Plot ground truth as SCATTER (blue) - sparse data, avoid implying smoothness\n    ax2.scatter(df_truth_cl['Energy'], df_truth_cl['CrossSection'], \n                s=80, c='tab:blue', marker='o', \n                label=f'Ground Truth ({len(df_truth_cl)} EXFOR pts)', \n                alpha=0.7, zorder=2, edgecolors='black', linewidths=1)\n    \n    # Plot Decision Tree prediction as LINE (red)\n    ax2.plot(energies_dt_cl, predictions_dt_cl, \n             'tab:red', linewidth=2.0, \n             label='Decision Tree (Extrapolation)', \n             alpha=0.8, zorder=1)\n    \n    # Configure axes: LOG-LOG\n    ax2.set_xscale('log')\n    ax2.set_yscale('log')\n    ax2.set_xlabel('Energy (eV)', fontsize=12, fontweight='bold')\n    ax2.set_ylabel('Cross Section (barns)', fontsize=12, fontweight='bold')\n    ax2.set_title('Cl-35 (n,p) (DATA-SPARSE): Transfer Learning Test\\n' + \n                  f'Only {len(df_truth_cl)} EXFOR measurements!\\n' +\n                  '(Model learned from other isotopes)',\n                  fontsize=13, fontweight='bold')\n    ax2.legend(fontsize=11, loc='best')\n    ax2.grid(True, alpha=0.3, which='both')  # Grid on both major and minor ticks\n    \n    # Annotate the challenge - use safe indexing\n    if len(predictions_dt_cl) > 250:\n        mid_idx = min(250, len(predictions_dt_cl) - 1)\n        anno_x = energies_dt_cl[mid_idx]\n        anno_y = predictions_dt_cl[mid_idx]\n        ax2.annotate('Can the model\\ntransfer knowledge?',\n                     xy=(anno_x, anno_y), \n                     xytext=(anno_x * 1.5, anno_y * 0.5),\n                     arrowprops=dict(arrowstyle='->', color='tab:red', lw=2),\n                     fontsize=10, color='tab:red', fontweight='bold',\n                     bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7))\nelse:\n    ax2.text(0.5, 0.5, 'No Cl-35 (n,p) data in range\\n(Check EXFOR ingestion or expand --max-files)',\n             ha='center', va='center', transform=ax2.transAxes, fontsize=11)\n    ax2.set_title('Cl-35 (n,p) (No Data)', fontsize=13, fontweight='bold')\n    ax2.set_xscale('log')\n    ax2.set_yscale('log')\n    ax2.grid(True, alpha=0.3, which='both')\n\nplt.tight_layout()\nplt.show()\n\n# ============================================================================\n# OBSERVATIONS\n# ============================================================================\n\nprint(\"\\n\u26a0\ufe0f  OBSERVATIONS:\")\nprint(\"=\"*80)\nprint(\"Training Approach: Model trained on FULL EXFOR database (all isotopes)\")\nprint(\"Evaluation: Testing predictions on U-235 and Cl-35\")\nprint()\nprint(\"LEFT (U-235 - Data-Rich in training):\")\nprint(\"  \u2022 Decision Tree creates JAGGED predictions even with lots of training data\")\nprint(\"  \u2022 Staircase effect would cause numerical instabilities in reactor codes\")\nprint(\"  \u2022 Blue scatter: EXFOR ground truth (cleaned and sorted)\")\nprint(\"  \u2022 Red line: Decision Tree prediction showing discontinuities\")\nprint()\nprint(\"RIGHT (Cl-35 - Data-Sparse, transfer learning):\")\nprint(\"  \u2022 Model must transfer knowledge from other isotopes\")\nprint(\"  \u2022 Large gaps between measurements \u2192 Predictions test generalization\")\nprint(\"  \u2022 Blue scatter: Sparse EXFOR measurements\")\nprint(\"  \u2022 Red line: Decision Tree extrapolation\")\nprint(\"  \u2022 This is where physics-informed models REALLY shine!\")\nprint(\"=\"*80)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### \ud83d\udd34 Critical Insight #1: Piecewise Constant \u2260 Physics\n",
        "\n",
        "Decision trees partition feature space into rectangles:\n",
        "```\n",
        "if Energy < 10.5:\n",
        "    if Energy < 5.2:\n",
        "        return 150.0  # Constant!\n",
        "    else:\n",
        "        return 89.0   # Jump!\n",
        "else:\n",
        "    return 45.0\n",
        "```\n",
        "\n",
        "Real physics:\n",
        "```\n",
        "\u03c3(E) = \u03c3_0 * \u0393 / ((E - E_r)\u00b2 + \u0393\u00b2/4)  # Smooth Breit-Wigner!\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Part 2: Can XGBoost Save Us?\n",
        "\n",
        "Let's try a more sophisticated ensemble method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize XGBoost\n",
        "xgb_naive = XGBoostEvaluator(\n",
        "    n_estimators=100,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.1,\n",
        ")\n",
        "\n",
        "# Train on naive features\n",
        "xgb_metrics_naive = xgb_naive.train(df_naive)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"XGBoost Performance (Naive Features):\")\n",
        "print(\"=\"*60)\n",
        "for key, value in xgb_metrics_naive.items():\n",
        "    if value is not None:\n",
        "        print(f\"  {key:20s}: {value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Get XGBoost predictions for U-235 (data-rich example)\nZ, A, mt_code = 92, 235, 18  # U-235 fission\nenergy_range = (1.0, 100.0)  # Resonance region\n\nenergies_xgb, predictions_xgb = xgb_naive.predict_resonance_region(\n    Z, A, mt_code, energy_range, num_points=1000, mode='naive'\n)\n\n# Get ground truth from evaluation dataset\nmask = (dataset_eval.df['Z'] == Z) & (dataset_eval.df['A'] == A) & (dataset_eval.df['MT'] == mt_code)\ndf_truth = dataset_eval.df[mask].copy()\ndf_truth = df_truth[(df_truth['Energy'] >= energy_range[0]) & (df_truth['Energy'] <= energy_range[1])]\n\n# Get Decision Tree predictions (from earlier)\nenergies_dt, predictions_dt = dt_model.predict_resonance_region(\n    Z, A, mt_code, energy_range, num_points=1000, mode='naive'\n)\n\n# Comparative plot\nfig, ax = plt.subplots(figsize=(12, 6))\n\n# Ground truth\nax.plot(df_truth['Energy'], df_truth['CrossSection'], \n        'b-', linewidth=3, label='Ground Truth (EXFOR)', alpha=0.7, zorder=1)\n\n# Decision Tree (stairs)\nax.plot(energies_dt, predictions_dt, \n        'r--', linewidth=1.5, label='Decision Tree (Staircase)', alpha=0.6, zorder=2)\n\n# XGBoost (smoother but not smooth)\nax.plot(energies_xgb, predictions_xgb, \n        'g-', linewidth=2, label='XGBoost (Better, but...)', alpha=0.8, zorder=3)\n\nax.set_xlabel('Energy (eV)', fontsize=12, fontweight='bold')\nax.set_ylabel('Cross Section (barns)', fontsize=12, fontweight='bold')\nax.set_title('XGBoost vs Decision Tree: Improvement but Still Not Physics-Compliant\\nU-235 Fission (Model trained on full EXFOR)',\n             fontsize=14, fontweight='bold')\nax.legend(fontsize=11)\nax.set_yscale('log')\nax.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\n\u2713 XGBoost is SMOOTHER (ensemble averaging)\")\nprint(\"\u2717 But still has micro-steps and can't guarantee smoothness\")\nprint(\"\u2717 No awareness of resonance physics\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### \ud83d\udfe1 Critical Insight #2: Ensembles Help, But...\n",
        "\n",
        "XGBoost averages many trees, which smooths predictions.\n",
        "\n",
        "**BUT:**\n",
        "- Still piecewise constant at fine scale\n",
        "- No guarantee of smoothness\n",
        "- Can't learn resonance physics (Breit-Wigner shape)\n",
        "- Poor extrapolation beyond training data\n",
        "\n",
        "---\n",
        "\n",
        "## Part 3: The Upgrade - Physics-Aware Features\n",
        "\n",
        "What if we give XGBoost *better features*?\n",
        "\n",
        "Instead of naive [Z, A, E, MT_onehot], use physics-derived features from the graph:\n",
        "- **Q-value**: Reaction energy\n",
        "- **Threshold**: E_threshold\n",
        "- **\u0394Z, \u0394A**: Nuclear topology\n",
        "\n",
        "This is the bridge to deep learning!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Get physics-aware tabular projection from FULL training dataset\ndf_physics = dataset_full.to_tabular(mode='physics')\n\nprint(\"Physics-Aware Features (trained on full EXFOR):\")\nprint(df_physics.columns.tolist())\nprint(f\"\\nDataset shape: {df_physics.shape}\")\nprint(f\"\\nFirst few rows:\")\ndf_physics.head()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train XGBoost with physics features\n",
        "xgb_physics = XGBoostEvaluator(\n",
        "    n_estimators=100,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.1,\n",
        ")\n",
        "\n",
        "xgb_metrics_physics = xgb_physics.train(df_physics)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"XGBoost Performance (Physics Features):\")\n",
        "print(\"=\"*60)\n",
        "for key, value in xgb_metrics_physics.items():\n",
        "    if value is not None:\n",
        "        print(f\"  {key:20s}: {value}\")\n",
        "\n",
        "print(\"\\nComparison with Naive Features:\")\n",
        "print(f\"  Test MSE (Naive):   {xgb_metrics_naive['test_mse']:.4e}\")\n",
        "print(f\"  Test MSE (Physics): {xgb_metrics_physics['test_mse']:.4e}\")\n",
        "improvement = (xgb_metrics_naive['test_mse'] - xgb_metrics_physics['test_mse']) / xgb_metrics_naive['test_mse'] * 100\n",
        "print(f\"  Improvement: {improvement:.1f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# Get physics-mode predictions for U-235\nenergies_xgb_phys, predictions_xgb_phys = xgb_physics.predict_resonance_region(\n    Z, A, mt_code, energy_range, num_points=1000, mode='physics'\n)\n\n# Final comparison\nfig, ax = plt.subplots(figsize=(14, 7))\n\n# Ground truth\nax.plot(df_truth['Energy'], df_truth['CrossSection'], \n        'b-', linewidth=3, label='Ground Truth (EXFOR)', alpha=0.8, zorder=1)\n\n# XGBoost naive\nax.plot(energies_xgb, predictions_xgb, \n        'orange', linewidth=2, linestyle='--', label='XGBoost (Naive Features)', alpha=0.6, zorder=2)\n\n# XGBoost physics\nax.plot(energies_xgb_phys, predictions_xgb_phys, \n        'g-', linewidth=2.5, label='XGBoost (Physics Features)', alpha=0.8, zorder=3)\n\nax.set_xlabel('Energy (eV)', fontsize=13, fontweight='bold')\nax.set_ylabel('Cross Section (barns)', fontsize=13, fontweight='bold')\nax.set_title('Physics Features Help... But We Can Do Better!\\nU-235 Fission Resonance Region (Model trained on full EXFOR)',\n             fontsize=15, fontweight='bold')\nax.legend(fontsize=12, loc='best')\nax.set_yscale('log')\nax.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\n\u2713 Physics features improve accuracy\")\nprint(\"\u2713 Model learns about thresholds and reaction energetics\")\nprint(\"\u2713 Training on full EXFOR allows transfer learning to specific isotopes\")\nprint(\"\u2717 STILL can't guarantee smooth resonance curves\")\nprint(\"\u2717 STILL poor extrapolation to unseen energy ranges\")\nprint(\"\u2717 No explicit physics constraints (unitarity, conservation laws)\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### \ud83d\udfe2 Critical Insight #3: Features Matter, But Architecture Matters More\n",
        "\n",
        "Physics-aware features help XGBoost understand reactions better.\n",
        "\n",
        "**BUT** the fundamental problem remains:\n",
        "- Tree-based models are **piecewise constant**\n",
        "- No inductive bias for **smoothness**\n",
        "- No way to encode **physical constraints**\n",
        "\n",
        "---\n",
        "\n",
        "## Part 4: Feature Importance Analysis\n",
        "\n",
        "Let's see what XGBoost \"thinks\" is important."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get feature importance\n",
        "importance_physics = xgb_physics.get_feature_importance()\n",
        "\n",
        "# Plot\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "ax.barh(importance_physics['Feature'], importance_physics['Importance'])\n",
        "ax.set_xlabel('Importance (Gain)', fontsize=12, fontweight='bold')\n",
        "ax.set_title('XGBoost Feature Importance (Physics Mode)', fontsize=14, fontweight='bold')\n",
        "ax.invert_yaxis()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nTop 5 Most Important Features:\")\n",
        "print(importance_physics.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### \ud83c\udf93 Key Takeaway\n\n> **Low MSE on test data does NOT guarantee safe reactor predictions!**\n>\n> We need models that:\n> 1. Respect physics (smoothness, thresholds, unitarity)\n> 2. Extrapolate correctly (beyond training data)\n> 3. Prioritize safety-critical reactions (sensitivity weighting)\n> 4. **Handle data-sparse scenarios** (like Cl-35) without overfitting\n>\n> This is why we need **Physics-Informed Deep Learning**.\n\n---\n\n## Summary: Why Classical ML Fails\n\n| Issue | U-235 (Data-Rich) | Cl-35 (Data-Sparse) |\n|-------|-------------------|---------------------|\n| Staircase Effect | \ud83d\udd34 Severe (even with lots of data) | \ud83d\udd34 Severe |\n| Interpolation | \ud83d\udfe1 Approximate | \ud83d\udd34 Very poor (large gaps) |\n| Extrapolation | \ud83d\udd34 Fails | \ud83d\udd34 Completely fails |\n| Physics Constraints | \ud83d\udd34 None | \ud83d\udd34 None |\n| Uncertainty Quantification | \ud83d\udd34 Poor | \ud83d\udd34 Very poor |\n| Training Speed | \ud83d\udfe2 Fast | \ud83d\udfe2 Fast |\n\n### The Path Forward\n\nWe need:\n1. **Graph Neural Networks** \u2192 Learn nuclear topology (not just Z, A)\n2. **Transformers** \u2192 Learn smooth energy sequences \u03c3(E)\n3. **Physics-Informed Loss** \u2192 Enforce unitarity, thresholds, conservation\n4. **Transfer Learning** \u2192 Use U-235 knowledge to improve Cl-35 predictions\n5. **Uncertainty Quantification** \u2192 Know when to trust sparse-data predictions\n\n---\n\n## Next Steps\n\nIn **Notebook 01**, we'll:\n- Build the **Chart of Nuclides as a Graph**\n- Visualize nuclear topology connecting U-235 and Cl-35\n- Understand how GNNs can transfer knowledge between isotopes\n\nIn **Notebook 02**, we'll:\n- Implement **GNN + Transformer**\n- Train on graph-structured real data\n- See **smooth, physics-compliant predictions** for both isotopes!\n\nIn **Notebook 03**, we'll:\n- Integrate with **OpenMC** for U-235 reactor validation\n- Achieve reactor-grade accuracy with real nuclear data\n- Demonstrate uncertainty quantification for Cl-35\n\nContinue to `01_Data_Fabric_and_Graph.ipynb` \u2192"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}