{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML for Nuclear Data: A Supervised Learning Starting Point\n",
    "\n",
    "This notebook trains and evaluates two classical supervised-learning models\n",
    "-- a Decision Tree and an XGBoost ensemble -- on neutron-induced\n",
    "cross-section data from the EXFOR database.\n",
    "\n",
    "### Why nuclear data?\n",
    "\n",
    "Nuclear cross sections describe the probability of a reaction occurring\n",
    "when a neutron strikes a target nucleus. They depend on:\n",
    "\n",
    "- **Energy** -- cross sections vary over many orders of magnitude as\n",
    "  incident energy changes from thermal (~0.01 eV) to fast (~20 MeV).\n",
    "- **Isotope** (Z, A) -- each target nucleus has a different cross-section\n",
    "  curve.\n",
    "- **Reaction channel** (MT code) -- fission, capture, elastic scattering,\n",
    "  (n,p), etc. each have distinct energy dependences.\n",
    "\n",
    "The EXFOR database aggregates experimental measurements from laboratories\n",
    "worldwide. Individual datasets vary in energy coverage, resolution, and\n",
    "reported uncertainties, making cross-section prediction a heterogeneous\n",
    "regression problem.\n",
    "\n",
    "### Supervised learning setup\n",
    "\n",
    "| | |\n",
    "|---|---|\n",
    "| **Inputs (features)** | Z, A, N, Energy, particle-emission vector, AME2020 nuclear properties |\n",
    "| **Target** | Cross section $\\sigma$ (barns) |\n",
    "| **Training set** | Full EXFOR database (all isotopes, neutron-induced) |\n",
    "| **Evaluation isotopes** | U-233 total XS (data-rich) and Cl-35 (n,p) (data-sparse) |\n",
    "\n",
    "### What this notebook covers\n",
    "\n",
    "- **Data loading** -- EXFOR measurements filtered to neutron-induced\n",
    "  reactions in the 0.01 eV -- 20 MeV range, with configurable feature tiers.\n",
    "- **Baseline models** -- Decision Tree and XGBoost, each with Bayesian\n",
    "  hyperparameter search so that results reflect tuned performance.\n",
    "- **Evaluation** -- predictions plotted against EXFOR data;\n",
    "  feature-importance analysis.\n",
    "- **Interpretation guidance** -- what the metrics and plots show, and what\n",
    "  to look for when reading the results.\n"
   ],
   "id": "cell-0"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Imports successful\n",
      "✓ EXFOR data found\n",
      "Welcome to NUCML-Next: Understanding ML Limitations with Real Nuclear Data\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "from nucml_next.data import NucmlDataset\n",
    "from nucml_next.baselines import XGBoostEvaluator, DecisionTreeEvaluator\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Verify EXFOR data exists\n",
    "exfor_path = Path('../data/exfor_test.parquet')\n",
    "if not exfor_path.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"EXFOR data not found at {exfor_path}\\n\"\n",
    "        \"Please run: python scripts/ingest_exfor.py --x4-db data/x4sqlite1.db --output data/exfor_processed.parquet\"\n",
    "    )\n",
    "\n",
    "print(\"✓ Imports successful\")\n",
    "print(\"✓ EXFOR data found\")\n",
    "print(\"Welcome to NUCML-Next: Understanding ML Limitations with Real Nuclear Data\")"
   ],
   "id": "cell-1"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "The cell below sets three groups of options that control the rest of the\n",
    "notebook:\n",
    "\n",
    "1. **Feature tiers** -- which AME2020 / NUBASE2020 nuclear-property columns\n",
    "   to include alongside the core coordinates (Z, A, N, Energy) and\n",
    "   particle-emission vector.\n",
    "2. **Transformation pipeline** -- log-scaling for energy and cross section,\n",
    "   optional feature standardisation.\n",
    "3. **Uncertainty weighting** -- whether to weight training samples by\n",
    "   inverse measurement uncertainty, and how to handle missing values.\n",
    "\n",
    "All settings are defined once here; every subsequent cell reads from these\n",
    "variables.\n"
   ],
   "id": "cell-2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# USER CONFIGURATION: Feature Tiers and Transformations\n",
    "# ============================================================================\n",
    "# Change these settings in ONE place instead of scattered throughout the notebook\n",
    "\n",
    "from nucml_next.data.selection import TransformationConfig\n",
    "\n",
    "# ============================================================================\n",
    "# FEATURE TIER SELECTION\n",
    "# ============================================================================\n",
    "# Choose which AME2020/NUBASE2020 enrichment tiers to include\n",
    "#\n",
    "# Tier A (13 features) - ALWAYS INCLUDED:\n",
    "#   - Z, A, N, Energy (nuclear coordinates)\n",
    "#   - 9-feature Numerical Particle Vector:\n",
    "#     out_n, out_p, out_a, out_g, out_f, out_t, out_h, out_d, is_met\n",
    "#\n",
    "# Tier B (+2 features) - Geometric:\n",
    "#   + R_fm (nuclear radius)\n",
    "#   + kR (dimensionless interaction parameter)\n",
    "#\n",
    "# Tier C (+7 features) - Energetics: RECOMMENDED FOR BASELINES\n",
    "#   + Mass_Excess_MeV (mass excess)\n",
    "#   + Binding_Energy_MeV (total binding energy)\n",
    "#   + Binding_Per_Nucleon_MeV (B/A)\n",
    "#   + S_1n_MeV, S_2n_MeV (neutron separation energies)\n",
    "#   + S_1p_MeV, S_2p_MeV (proton separation energies)\n",
    "#\n",
    "# Tier D (+9 features) - Topological:\n",
    "#   + Spin, Parity (nuclear structure)\n",
    "#   + Isomer_Level, Half_Life_log10_s (log10-transformed half-life)\n",
    "#   + Valence_N, Valence_P (distance to magic numbers)\n",
    "#   + P_Factor (pairing: even-even/odd-odd)\n",
    "#   + Shell_Closure_N, Shell_Closure_P\n",
    "#\n",
    "# Tier E (+8 features) - Complete Q-values:\n",
    "#   + Q_alpha_MeV, Q_2beta_minus_MeV, Q_ep_MeV, etc.\n",
    "#   + All 8 reaction Q-values from AME2020\n",
    "\n",
    "SELECTED_TIERS = ['A', 'C']  # Change tiers HERE (only place to modify)\n",
    "\n",
    "print(f\"Selected Feature Tiers: {SELECTED_TIERS}\")\n",
    "print(f\"   Features: Tier A (core + particle vector) + Tier C (energetics)\")\n",
    "print()\n",
    "\n",
    "# ============================================================================\n",
    "# TRANSFORMATION CONFIGURATION\n",
    "# ============================================================================\n",
    "# Configure log-scaling and feature scaling for ML training.\n",
    "#\n",
    "# ORDER OF OPERATIONS (forward transform):\n",
    "#   1. Log-transform cross-section: sigma' = log10(sigma + epsilon)\n",
    "#   2. Log-transform energy:        E' = log10(E)\n",
    "#   3. Scale ALL features:          X' = (X - min) / (max - min)\n",
    "#\n",
    "# This ensures the scaler sees compressed log-space values rather than\n",
    "# raw multi-order-of-magnitude physical values.\n",
    "#\n",
    "# For tree-based models (Decision Trees, XGBoost), feature scaling is NOT\n",
    "# mathematically necessary because trees only use value ordering.\n",
    "# However, MinMax scaling is cheap and doesn't hurt -- and it prepares\n",
    "# the pipeline for neural networks where scaling IS required.\n",
    "\n",
    "TRANSFORMATION_CONFIG = TransformationConfig(\n",
    "    # ============================================================================\n",
    "    # Target (cross-section) transformations\n",
    "    # ============================================================================\n",
    "    log_target=True,              # Enable log10 transform for cross-sections\n",
    "                                  # Stabilizes gradients and handles wide range (ub to kb)\n",
    "    \n",
    "    target_epsilon=1e-10,         # Epsilon for log(xs + epsilon) to prevent log(0)\n",
    "                                  # Increase if you have very small cross-sections\n",
    "    \n",
    "    log_base=10,                  # Logarithm base: 10 | 'e' | 2\n",
    "                                  # Base-10 is standard in nuclear physics\n",
    "    \n",
    "    # ============================================================================\n",
    "    # Energy transformations\n",
    "    # ============================================================================\n",
    "    log_energy=True,              # Enable log10 transform for energies\n",
    "                                  # Handles wide energy range (eV to MeV)\n",
    "    \n",
    "    energy_log_base=10,           # Energy log base: 10 | 'e' | 2\n",
    "    \n",
    "    # ============================================================================\n",
    "    # Feature standardization (MinMax, Z-score, etc.)\n",
    "    # ============================================================================\n",
    "    # Order: Log-transforms are applied FIRST, then feature scaling.\n",
    "    # The scaler is fitted on log-transformed values, so Energy in the\n",
    "    # scaler's view is log10(E), not raw eV.\n",
    "    \n",
    "    scaler_type='minmax',         # Feature scaling method:\n",
    "                                  # 'minmax'   = Min-max scaling to [0,1] [DEFAULT]\n",
    "                                  # 'standard' = Z-score normalization (X-mu)/sigma\n",
    "                                  # 'robust'   = Robust scaling using median and IQR\n",
    "                                  # 'none'     = No scaling\n",
    "    \n",
    "    scale_features='all',         # Which columns to scale:\n",
    "                                  # 'all'  = Scale every numeric column [DEFAULT]\n",
    "                                  # None   = Auto-detect numeric columns (same as 'all')\n",
    "                                  # List   = Explicit column names, e.g. ['Z', 'A', 'Energy']\n",
    ")\n",
    "\n",
    "print(\"Transformation Configuration:\")\n",
    "print(TRANSFORMATION_CONFIG)\n",
    "print()\n",
    "print(\"NOTE: MinMax scaling applied to ALL features AFTER log-transforms.\")\n",
    "print(\"      Trees are scale-invariant, but this prepares the pipeline\")\n",
    "print(\"      for neural networks and doesn't hurt tree performance.\")\n",
    "print()\n",
    "\n",
    "# ============================================================================\n",
    "# UNCERTAINTY WEIGHTING CONFIGURATION\n",
    "# ============================================================================\n",
    "# Configure how to use experimental uncertainties during training.\n",
    "#\n",
    "# The EXFOR database contains measurement uncertainties for ~66% of cross-section\n",
    "# values. These uncertainties can be used to weight samples during training,\n",
    "# giving more influence to precise measurements and less to uncertain ones.\n",
    "#\n",
    "# Statistical basis: Inverse-variance weighting (w_i = 1/sigma_i^2) is the\n",
    "# optimal weighting for least-squares regression when errors are heteroscedastic.\n",
    "\n",
    "USE_UNCERTAINTY_WEIGHTS = 'xs'    # Uncertainty weighting mode:\n",
    "                                  # None   = No weighting (equal weight)\n",
    "                                  # 'xs'   = Weight by cross-section uncertainty (1/sigma_xs^2)\n",
    "                                  # 'both' = Weight by XS AND energy uncertainty\n",
    "                                  #          (1/sigma_xs^2 * 1/sigma_E^2)\n",
    "\n",
    "MISSING_UNCERTAINTY_HANDLING = 'exclude'\n",
    "                                  # How to handle samples with missing uncertainties\n",
    "                                  # (only used when USE_UNCERTAINTY_WEIGHTS is not None):\n",
    "                                  # 'median'  = Assign median weight from valid samples (default)\n",
    "                                  # 'equal'   = Assign weight of 1.0\n",
    "                                  # 'exclude' = Exclude samples without valid uncertainty\n",
    "                                  #             (equivalent to requiring uncertainty)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"Uncertainty Weighting Configuration:\")\n",
    "print(f\"  USE_UNCERTAINTY_WEIGHTS:       {USE_UNCERTAINTY_WEIGHTS}\")\n",
    "print(f\"  MISSING_UNCERTAINTY_HANDLING:  '{MISSING_UNCERTAINTY_HANDLING}'\")\n",
    "if USE_UNCERTAINTY_WEIGHTS:\n",
    "    print(f\"\\n  NOTE: Uncertainty weighting enabled (mode='{USE_UNCERTAINTY_WEIGHTS}').\")\n",
    "    print(\"        Samples with lower uncertainty get higher weight.\")\n",
    "    if MISSING_UNCERTAINTY_HANDLING == 'exclude':\n",
    "        print(\"\\n  NOTE: MISSING_UNCERTAINTY_HANDLING='exclude' will filter to only\")\n",
    "        print(\"        samples with valid uncertainty (~66% of data).\")\n",
    "print()\n",
    "print(\"To change settings, modify SELECTED_TIERS and TRANSFORMATION_CONFIG above\")\n",
    "print(\"=\" * 80)"
   ],
   "id": "cell-3"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier Detection & Interactive Threshold Selection\n",
    "\n",
    "The ingested Parquet contains outlier detection results (if `--outlier-method` \n",
    "was used during ingestion). Two methods are available:\n",
    "\n",
    "**Local MAD method (recommended):**\n",
    "- Fits a smooth mean on pooled data per (Z, A, MT) group\n",
    "- Computes energy-local MAD (median absolute deviation) of residuals\n",
    "- Flags individual points with z > threshold as point outliers\n",
    "- Flags entire experiments where a high fraction of points exceed threshold\n",
    "- Columns: `experiment_outlier`, `point_outlier`, `z_score`, `experiment_id`\n",
    "\n",
    "**Legacy SVGP method:**\n",
    "- Pools all experiments per (Z, A, MT) group\n",
    "- Point-level z-scores only\n",
    "\n",
    "The interactive explorer below lets you browse any (Z, A, MT) group, \n",
    "visualise the z-score distribution, adjust the z-score threshold, \n",
    "and see how inlier/outlier counts change in real time.\n",
    "\n",
    "If the Parquet does **not** contain outlier columns, this section is skipped\n",
    "automatically and all data is retained."
   ],
   "id": "cell-4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Interactive Outlier Threshold Explorer ────────────────────────────────────\n",
    "# Select any (Z, A, MT) group, adjust the z-score threshold, and inspect\n",
    "# the smooth mean fit + z-score bands interactively.\n",
    "\n",
    "EXFOR_DATA_PATH = '../data/exfor_processed.parquet'\n",
    "ENDF_DIR = '../data/ENDF-B/neutrons'\n",
    "\n",
    "\n",
    "# Check for outlier detection columns (supports both local MAD and SVGP methods)\n",
    "_check_cols = ['z_score', 'experiment_outlier', 'experiment_id', 'point_outlier']\n",
    "try:\n",
    "    import pyarrow.parquet as pq\n",
    "    pq_file = pq.ParquetFile(EXFOR_DATA_PATH)\n",
    "    _available_cols = pq_file.schema.names\n",
    "    _cols_to_load = [c for c in _check_cols if c in _available_cols]\n",
    "    if _cols_to_load:\n",
    "        _raw_check = pd.read_parquet(EXFOR_DATA_PATH, columns=_cols_to_load)\n",
    "    else:\n",
    "        _raw_check = pd.DataFrame()\n",
    "except Exception:\n",
    "    _raw_check = pd.DataFrame()\n",
    "\n",
    "has_outlier_data = 'z_score' in _raw_check.columns and _raw_check['z_score'].notna().any()\n",
    "has_experiment_outlier = 'experiment_outlier' in _raw_check.columns\n",
    "\n",
    "if has_outlier_data:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"OUTLIER DETECTION DATA FOUND\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    if has_experiment_outlier:\n",
    "        print(\"Method: Local MAD (smooth mean + energy-local MAD)\")\n",
    "        print(\"  - point_outlier: individual measurements with z > threshold\")\n",
    "        print(\"  - experiment_outlier: experiments with high fraction of flagged points\")\n",
    "        print(\"  - z_score: |deviation from consensus| / local scatter\")\n",
    "        print()\n",
    "        print(\"Use 'Color by experiment' toggle to visualize individual experiments\")\n",
    "        print(\"Discrepant experiments are marked with red X markers\")\n",
    "    else:\n",
    "        print(\"Method: Legacy SVGP (point-level only)\")\n",
    "        print(\"  - z_score: deviation from pooled SVGP fit\")\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "    \n",
    "    from nucml_next.visualization.threshold_explorer import ThresholdExplorer\n",
    "    explorer = ThresholdExplorer(EXFOR_DATA_PATH, endf_dir=ENDF_DIR)\n",
    "    explorer.show()\n",
    "else:\n",
    "    print(\"Outlier columns not found -- run ingestion with --outlier-method to enable\")\n",
    "    print(\"  Local MAD (recommended):      --outlier-method local_mad\")\n",
    "    print(\"  Legacy SVGP:                  --outlier-method svgp\")\n",
    "    print(\"\\nProceeding without outlier filtering.\\n\")\n",
    "\n",
    "# Store for use in cell 6\n",
    "_HAS_EXPERIMENT_OUTLIER = has_experiment_outlier\n",
    "del _raw_check"
   ],
   "id": "cell-5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Get filter settings from explorer ─────────────────────────────────────────\n",
    "# The ThresholdExplorer provides interactive controls for:\n",
    "#   - z-score threshold (slider)\n",
    "#   - Exclude point outliers (checkbox)\n",
    "#   - Exclude discrepant experiments (checkbox)\n",
    "#\n",
    "# After configuring the explorer above, run this cell to capture the settings.\n",
    "\n",
    "# ============================================================================\n",
    "# GET SETTINGS FROM EXPLORER\n",
    "# ============================================================================\n",
    "if has_outlier_data and 'explorer' in dir():\n",
    "    # Get current settings from explorer checkboxes\n",
    "    FILTER_SETTINGS = explorer.get_filter_settings()\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"OUTLIER FILTER SETTINGS (from explorer)\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"  z_threshold:                    {FILTER_SETTINGS['z_threshold']}\")\n",
    "    print(f\"  exclude_point_outliers:         {FILTER_SETTINGS['exclude_point_outliers']}\")\n",
    "    print(f\"  exclude_discrepant_experiments: {FILTER_SETTINGS['exclude_discrepant_experiments']}\")\n",
    "    print()\n",
    "    print(\"These settings will be applied when loading training data in the next cell.\")\n",
    "    print(\"To change settings, adjust the checkboxes in the explorer and re-run this cell.\")\n",
    "    print(\"=\" * 80)\n",
    "else:\n",
    "    # Fallback: no outlier data or explorer not initialized\n",
    "    FILTER_SETTINGS = {\n",
    "        'z_threshold': None,\n",
    "        'exclude_point_outliers': False,\n",
    "        'exclude_discrepant_experiments': False,\n",
    "    }\n",
    "    print(\"=\" * 80)\n",
    "    print(\"OUTLIER FILTER SETTINGS\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"No outlier data available - all data will be used for training.\")\n",
    "    print(\"To enable outlier filtering, run ingestion with --outlier-method local_mad\")\n",
    "    print(\"=\" * 80)"
   ],
   "id": "cell-6"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data: EXFOR-derived processed dataset\n",
    "\n",
    "The notebook loads a Parquet file produced by the NUCML-Next ingestion\n",
    "pipeline (`scripts/ingest_exfor.py`). A `DataSelection` object specifies\n",
    "the selection constraints used here for consistency:\n",
    "\n",
    "- **Projectile**: neutron only.\n",
    "- **Energy range**: 1e-5 eV to 2e7 eV (thermal through fast reactor\n",
    "  energies).\n",
    "- **Reaction channels**: all physical MT codes, including bookkeeping\n",
    "  channels (MT 0, 1, >= 9000).\n",
    "- **Validity filter**: rows with NaN or non-positive cross sections are\n",
    "  dropped so that log-transforms are well-defined.\n",
    "\n",
    "The full training set contains all isotopes. Two evaluation isotopes are\n",
    "loaded separately:\n",
    "\n",
    "| Isotope | Reaction | Role |\n",
    "|---------|----------|------|\n",
    "| U-233 | Total XS (MT 1) | Data-rich: thousands of EXFOR points |\n",
    "| Cl-35 | (n,p) (MT 103) | Data-sparse: tens of EXFOR points |\n",
    "\n",
    "Comparing a data-rich and a data-sparse case illustrates how model\n",
    "behaviour changes with measurement density.\n"
   ],
   "id": "cell-7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T21:33:01.695938Z",
     "iopub.status.busy": "2026-01-26T21:33:01.694354Z",
     "iopub.status.idle": "2026-01-26T21:34:53.672027Z",
     "shell.execute_reply": "2026-01-26T21:34:53.655001Z"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# DATA SELECTION & LOADING\n",
    "# ============================================================================\n",
    "# Physics-aware selection with predicate pushdown for efficient loading.\n",
    "\n",
    "from nucml_next.data import DataSelection\n",
    "from nucml_next.experiment import HoldoutConfig, ExperimentManager, compute_holdout_metrics\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"DATA SELECTION & LOADING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ============================================================================\n",
    "# PHASE-SPACE HOLDOUT CONFIGURATION\n",
    "# ============================================================================\n",
    "# Define holdout rules to measure extrapolation accuracy on unseen data.\n",
    "# Rules are AND-intersected within, OR-unioned across (any match => holdout).\n",
    "#\n",
    "# Supported keys:\n",
    "#   Z, A            — isotope (int)\n",
    "#   MT              — reaction channel (int or list)\n",
    "#   energy_range    — (E_min, E_max) in eV\n",
    "#   xs_range        — (XS_min, XS_max) in barns\n",
    "#   Entry           — EXFOR Entry ID(s) (str or list)\n",
    "#\n",
    "# Examples (uncomment to enable):\n",
    "#   {'Z': 92, 'A': 233}                         — hold out ALL U-233 data\n",
    "#   {'Z': 92, 'A': 235, 'MT': 102,\n",
    "#    'energy_range': (1e-3, 1.0)}               — U-235 capture in resonance region\n",
    "#   {'MT': 18}                                  — hold out ALL fission data\n",
    "#   {'xs_range': (1e-6, 1e-3)}                  — hold out low cross-section points\n",
    "\n",
    "HOLDOUT_CONFIG = HoldoutConfig(rules=[\n",
    "    # ── Uncomment rules below to enable holdout ──────────────────────────\n",
    "    # {'Z': 92, 'A': 233},\n",
    "    # {'Z': 92, 'A': 235, 'MT': 102, 'energy_range': (1e-3, 1.0)},\n",
    "    # {'MT': 18},\n",
    "])\n",
    "\n",
    "holdout_config = HOLDOUT_CONFIG if HOLDOUT_CONFIG.rules else None\n",
    "\n",
    "if holdout_config:\n",
    "    print(f\"\\nPhase-Space Holdout: {len(holdout_config.rules)} rule(s)\")\n",
    "    print(holdout_config)\n",
    "else:\n",
    "    print(\"\\nPhase-Space Holdout: DISABLED\")\n",
    "\n",
    "# ============================================================================\n",
    "# OUTLIER FILTERING (from explorer settings in cell 6)\n",
    "# ============================================================================\n",
    "# These settings come from the ThresholdExplorer checkboxes\n",
    "_z_threshold = FILTER_SETTINGS.get('z_threshold')\n",
    "_exclude_point = FILTER_SETTINGS.get('exclude_point_outliers', False)\n",
    "_exclude_exp = FILTER_SETTINGS.get('exclude_discrepant_experiments', False)\n",
    "\n",
    "print(f\"\\nOutlier Filtering:\")\n",
    "print(f\"  z_threshold:                    {_z_threshold}\")\n",
    "print(f\"  exclude_point_outliers:         {_exclude_point}\")\n",
    "print(f\"  exclude_discrepant_experiments: {_exclude_exp}\")\n",
    "\n",
    "# ============================================================================\n",
    "# DATA SELECTION\n",
    "# ============================================================================\n",
    "training_selection = DataSelection(\n",
    "    # ========================================================================\n",
    "    # PROJECTILE SELECTION\n",
    "    # ========================================================================\n",
    "    projectile='neutron',          # Options: 'neutron' | 'all' | '<code>' | ['<code>', ...]\n",
    "                                   # 'neutron' = Only neutron-induced reactions (alias for 'n')\n",
    "                                   # 'all'     = All projectiles, no filtering\n",
    "                                   # 'n'       = Neutrons only (same as 'neutron')\n",
    "                                   # 'p'       = Protons only\n",
    "                                   # 'd'       = Deuterons only\n",
    "                                   # 'a'       = Alphas only\n",
    "                                   # 'g'       = Photons (gamma) only\n",
    "                                   # 't'       = Tritons only\n",
    "                                   # 'he3'     = Helium-3 only\n",
    "                                   # ['n','p'] = Neutrons + protons\n",
    "                                   # ['n','a','d'] = Custom combination\n",
    "\n",
    "    # ========================================================================\n",
    "    # ENERGY RANGE (eV)\n",
    "    # ========================================================================\n",
    "    energy_min=1e-5,               # Minimum energy in eV (1e-5 = 0.01 eV, thermal neutrons)\n",
    "    energy_max=2e7,                # Maximum energy in eV (2e7 = 20 MeV, reactor physics upper bound)\n",
    "                                   # Common ranges:\n",
    "                                   #   - Thermal: 1e-5 to 1 eV\n",
    "                                   #   - Resonance: 1 to 1e4 eV\n",
    "                                   #   - Fast: 1e4 to 2e7 eV (20 MeV)\n",
    "                                   #   - High energy: up to 1e9 eV (1 GeV)\n",
    "\n",
    "    # ========================================================================\n",
    "    # REACTION (MT) MODE SELECTION\n",
    "    # ========================================================================\n",
    "    mt_mode='all_physical',        # Options:\n",
    "                                   # 'reactor_core'   → Essential for reactor modeling\n",
    "                                   #                    (MT 2, 4, 16, 18, 102, 103, 107)\n",
    "                                   #\n",
    "                                   # 'threshold_only' → Reactions with energy thresholds\n",
    "                                   #                    (MT 16, 17, 103, 104, 105, 106, 107)\n",
    "                                   #\n",
    "                                   # 'fission_details'→ Fission breakdown channels\n",
    "                                   #                    (MT 18, 19, 20, 21, 38)\n",
    "                                   #\n",
    "                                   # 'all_physical'   → All MT codes (subject to exclude_mt)\n",
    "                                   #\n",
    "                                   # 'custom'         → Use custom_mt_codes list (see below)\n",
    "\n",
    "    # ========================================================================\n",
    "    # MT EXCLUSION LIST\n",
    "    # ========================================================================\n",
    "    # Specific MT codes to exclude from the dataset.\n",
    "    # Each entry is a literal MT number, EXCEPT that 9000 is a sentinel\n",
    "    # meaning \"exclude all MT >= 9000\" (lumped covariance / residual production).\n",
    "    #\n",
    "    # Examples:\n",
    "    #   exclude_mt=[0]           — exclude only MT 0 (undefined/non-standard)\n",
    "    #   exclude_mt=[0, 9000]     — also remove all MT >= 9000\n",
    "    #   exclude_mt=[]            — include everything (no exclusions)\n",
    "    #   exclude_mt=None          — include everything (no exclusions)\n",
    "    exclude_mt=[],                 # No exclusions — include MT 0, 1, and MT >= 9000\n",
    "\n",
    "    exclude_spectrum_averaged=True, # Exclude MXW, SPA, FIS, AV, BRA, BRS, SDT, FST, TTA\n",
    "                                    # These are spectrum-averaged (non-monoenergetic) data\n",
    "                                    # where \"Energy\" = characteristic spectrum energy,\n",
    "                                    # not the actual incident energy.\n",
    "                                    # Set False to include all sf8 types.\n",
    "\n",
    "    # ========================================================================\n",
    "    # DATA VALIDITY\n",
    "    # ========================================================================\n",
    "    drop_invalid=True,             # Drop NaN or non-positive cross-sections\n",
    "                                   # Essential for log-transform: log(σ) requires σ > 0\n",
    "                                   # Prevents training instabilities\n",
    "\n",
    "    # ========================================================================\n",
    "    # PHASE-SPACE HOLDOUT\n",
    "    # ========================================================================\n",
    "    holdout_config=holdout_config, # HoldoutConfig with intersection/union rule logic\n",
    "                                   # Replaces the legacy holdout_isotopes parameter\n",
    "                                   # Set to None to disable holdout filtering\n",
    "\n",
    "    # ========================================================================\n",
    "    # AME2020/NUBASE2020 ENRICHMENT TIER SELECTION\n",
    "    # ========================================================================\n",
    "    tiers=SELECTED_TIERS,          # Using centralized tier configuration from cell 3\n",
    "    transformation_config=TRANSFORMATION_CONFIG,  # Using centralized transformation config\n",
    "\n",
    "    # ========================================================================\n",
    "    # OUTLIER FILTERING (from explorer settings)\n",
    "    # ========================================================================\n",
    "    z_threshold=_z_threshold if _exclude_point else None,\n",
    "    include_outliers=not _exclude_point,\n",
    "    exclude_discrepant_experiments=_exclude_exp,\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"Training Selection:\")\n",
    "print(training_selection)\n",
    "\n",
    "# ============================================================================\n",
    "# LOAD DATASET\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"Loading dataset with predicate pushdown...\")\n",
    "dataset_full = NucmlDataset(\n",
    "    data_path='../data/exfor_processed.parquet',\n",
    "    mode='tabular',\n",
    "    selection=training_selection,\n",
    ")\n",
    "\n",
    "# Retrieve holdout data (if configured)\n",
    "df_holdout = dataset_full.get_holdout_data()\n",
    "if df_holdout is not None:\n",
    "    print(f\"\\n[OK] Holdout reserved: {len(df_holdout):,} points \"\n",
    "          f\"({df_holdout.groupby(['Z','A']).ngroups} isotopes)\")\n",
    "else:\n",
    "    print(\"\\n[--] No holdout data\")\n",
    "\n",
    "# ============================================================================\n",
    "# PROJECT TO TABULAR FORMAT\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"Projecting to tabular format (particle vector)...\")\n",
    "_extra_meta = ['Energy_Uncertainty'] if USE_UNCERTAINTY_WEIGHTS == 'both' else None\n",
    "df_tier = dataset_full.to_tabular(extra_metadata=_extra_meta)\n",
    "\n",
    "print(f\"\\n[OK] Training set: {len(df_tier):,} samples x {len(df_tier.columns)} columns\")\n",
    "print(f\"     Energy range: {df_tier['Energy'].min():.2e} – {df_tier['Energy'].max():.2e} eV\")\n",
    "\n",
    "# ============================================================================\n",
    "# UNCERTAINTY COVERAGE SUMMARY\n",
    "# ============================================================================\n",
    "if 'Uncertainty' in df_tier.columns:\n",
    "    valid_unc = df_tier['Uncertainty'].notna() & (df_tier['Uncertainty'] > 0)\n",
    "    pct = 100 * valid_unc.sum() / len(df_tier)\n",
    "    print(f\"     XS uncertainty: {valid_unc.sum():,} / {len(df_tier):,} ({pct:.1f}%)\")\n",
    "\n",
    "# ============================================================================\n",
    "# FEATURE SUMMARY\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(f\"Feature Tiers: {SELECTED_TIERS}\")\n",
    "TIER_NAMES = {'A': 'Core+Particle', 'B': 'Geometric', 'C': 'Energetics',\n",
    "              'D': 'Topological', 'E': 'Q-values'}\n",
    "for t in SELECTED_TIERS:\n",
    "    print(f\"  Tier {t}: {TIER_NAMES.get(t, 'Unknown')}\")\n",
    "\n",
    "# ============================================================================\n",
    "# DATA DISTRIBUTION\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"Top 10 Isotopes:\")\n",
    "for (z, a), cnt in dataset_full.df.groupby(['Z', 'A']).size().nlargest(10).items():\n",
    "    elem = {92:'U', 17:'Cl', 94:'Pu', 26:'Fe', 8:'O', 1:'H', 82:'Pb',\n",
    "            6:'C', 13:'Al', 7:'N', 11:'Na', 79:'Au'}.get(z, f'Z{z}')\n",
    "    print(f\"  {elem}-{a:3d}: {cnt:>8,}\")\n",
    "\n",
    "print(f\"\\nTotal: {dataset_full.df.groupby(['Z','A']).ngroups} isotopes, \"\n",
    "      f\"{dataset_full.df['MT'].nunique()} MT codes, {len(dataset_full.df):,} points\")\n",
    "\n",
    "# ============================================================================\n",
    "# LOAD EVALUATION ISOTOPES (U-233, Cl-35)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"Loading evaluation targets (U-233, Cl-35)...\")\n",
    "eval_selection = DataSelection(\n",
    "    projectile='neutron',\n",
    "    energy_min=training_selection.energy_min,\n",
    "    energy_max=training_selection.energy_max,\n",
    "    mt_mode=training_selection.mt_mode,\n",
    "    exclude_mt=training_selection.exclude_mt,\n",
    "    exclude_spectrum_averaged=True,\n",
    "    drop_invalid=True,\n",
    "    tiers=SELECTED_TIERS,\n",
    ")\n",
    "\n",
    "dataset_eval = NucmlDataset(\n",
    "    data_path='../data/exfor_processed.parquet',\n",
    "    mode='tabular',\n",
    "    selection=eval_selection,\n",
    ")\n",
    "dataset_eval.df = dataset_eval.df[\n",
    "    ((dataset_eval.df['Z'] == 92) & (dataset_eval.df['A'] == 233)) |\n",
    "    ((dataset_eval.df['Z'] == 17) & (dataset_eval.df['A'] == 35))\n",
    "].copy()\n",
    "\n",
    "print(f\"[OK] Evaluation set: {len(dataset_eval.df):,} points\")\n",
    "for (z, a), grp in dataset_eval.df.groupby(['Z', 'A']):\n",
    "    iso = 'U' if z == 92 else 'Cl'\n",
    "    print(f\"     {iso}-{a}: {len(grp):,} (MT: {sorted(grp['MT'].unique())})\")\n",
    "print(\"=\" * 80)"
   ],
   "id": "cell-8"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature representation\n",
    "\n",
    "Reaction channels (MT codes) are encoded as a 9-component\n",
    "**particle-emission vector** (`out_n`, `out_p`, `out_a`, ..., `is_met`)\n",
    "rather than one-hot indicators. This preserves information about which\n",
    "particles are emitted in each reaction.\n",
    "\n",
    "If Tier C is selected, seven AME2020 energetics columns (mass excess,\n",
    "binding energies, separation energies) are appended. The full set of\n",
    "available tiers is documented in the configuration cell above.\n"
   ],
   "id": "cell-9"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline 1 -- Decision Tree\n",
    "\n",
    "A single Decision Tree is trained on the full EXFOR dataset. To ensure the\n",
    "results reflect a well-tuned model rather than arbitrary defaults, Bayesian\n",
    "hyperparameter optimisation (hyperopt with TPE) is run first, and the best\n",
    "parameters are then used to train on the complete training set.\n",
    "\n",
    "A Decision Tree partitions feature space into axis-aligned rectangles,\n",
    "returning a constant prediction within each rectangle. The resulting\n",
    "cross-section curve is therefore piecewise constant by construction.\n"
   ],
   "id": "cell-10"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T21:34:53.746941Z",
     "iopub.status.busy": "2026-01-26T21:34:53.743177Z",
     "iopub.status.idle": "2026-01-26T21:45:39.106787Z",
     "shell.execute_reply": "2026-01-26T21:45:39.099894Z"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# HYPERPARAMETER OPTIMIZATION FOR DECISION TREE\n",
    "# ============================================================================\n",
    "# Find good hyperparameters using one of the available search strategies.\n",
    "# The final model is always retrained on FULL data with the best parameters.\n",
    "\n",
    "# ============================================================================\n",
    "# USER CONFIGURATION: Hyperparameter Search Space\n",
    "# ============================================================================\n",
    "\n",
    "# ============================================================================\n",
    "# OPTIMIZATION METHOD SELECTION\n",
    "# ============================================================================\n",
    "# Choose the hyperparameter search strategy:\n",
    "#\n",
    "# 'bayesian' (RECOMMENDED):\n",
    "#   - Uses Tree-structured Parzen Estimator (TPE) via hyperopt\n",
    "#   - Most sample-efficient; learns from previous evaluations\n",
    "#   - Best for expensive model evaluations and complex parameter interactions\n",
    "#   - Requires: pip install hyperopt\n",
    "#\n",
    "# 'grid':\n",
    "#   - Exhaustive search over all parameter combinations\n",
    "#   - Guaranteed to find optimum within the grid\n",
    "#   - Time complexity: O(n^k) - exponential in number of parameters\n",
    "#   - Best for: Small search spaces where exhaustive search is feasible\n",
    "#\n",
    "# 'random':\n",
    "#   - Randomly samples parameter combinations\n",
    "#   - Typically finds good solutions faster than grid search\n",
    "#   - Good for: Large search spaces, continuous parameters\n",
    "#\n",
    "# 'halving':\n",
    "#   - Successive halving strategy (HalvingRandomSearchCV)\n",
    "#   - Progressively eliminates poor candidates using data subsets\n",
    "#   - Much faster than full random search on large datasets\n",
    "#   - Requires: sklearn >= 0.24\n",
    "\n",
    "DT_OPTIMIZATION_METHOD = 'bayesian'  # Options: 'bayesian' | 'grid' | 'random' | 'halving'\n",
    "\n",
    "# max_depth: Maximum tree depth\n",
    "DT_MIN_DEPTH = 60\n",
    "DT_MAX_DEPTH = 90\n",
    "DT_DEPTH_STEP = 2          # choices: 60, 62, 64, ..., 90\n",
    "\n",
    "# min_samples_split: Minimum samples required to split an internal node\n",
    "DT_MIN_MSS = 2\n",
    "DT_MAX_MSS = 16\n",
    "DT_MSS_STEP = 2            # choices: 2, 4, 6, ..., 16\n",
    "\n",
    "# min_samples_leaf: Minimum samples required at a leaf node\n",
    "DT_MIN_MSL = 1\n",
    "DT_MAX_MSL = 12\n",
    "DT_MSL_STEP = 1            # choices: 1, 2, 3, ..., 12\n",
    "\n",
    "# min_impurity_decrease: Minimum impurity decrease required for a split.\n",
    "# Default 0.0 means no regularization via impurity threshold.\n",
    "# When subsampling for hyperparameter search, absolute impurity thresholds\n",
    "# found on subsampled data over-regularize on full data (e.g. depth 36,\n",
    "# 1085 leaves on 8M samples). The structural params (max_depth, mss, msl)\n",
    "# already control complexity and generalise correctly from subsample to\n",
    "# full data. Set to a small positive value (e.g. 1e-7) only if you observe\n",
    "# severe overfitting.\n",
    "DT_MIN_IMPURITY_DECREASE = 0.0\n",
    "\n",
    "# Bayesian search budget (only used when DT_OPTIMIZATION_METHOD = 'bayesian')\n",
    "DT_MAX_EVALS = 200         # number of hyperopt trials\n",
    "\n",
    "# ============================================================================\n",
    "# VALIDATION STRATEGY\n",
    "# ============================================================================\n",
    "# How to evaluate candidate hyperparameters during the search.\n",
    "#\n",
    "# 'holdout' (default):\n",
    "#   Splits data into train / val / test.\n",
    "#   Each hyperopt trial trains on \"train\" and evaluates on \"val\".\n",
    "#   The final model is retrained on train+val and scored on the \"test\" set.\n",
    "#   Faster and simpler -- recommended for large datasets.\n",
    "#\n",
    "# 'kfold':\n",
    "#   Each hyperopt trial runs k-fold CV on the train+val portion.\n",
    "#   The final model is retrained on train+val and scored on a held-out test set.\n",
    "#   More robust estimate of generalisation but k-times slower per trial.\n",
    "\n",
    "DT_VALIDATION_METHOD = 'holdout'   # 'holdout' or 'kfold'\n",
    "\n",
    "# Holdout split percentages (must sum to 1.0)\n",
    "DT_TRAIN_FRACTION = 0.70          # 70% for training during search\n",
    "DT_VAL_FRACTION   = 0.15          # 15% for validation during search\n",
    "DT_TEST_FRACTION  = 0.15          # 15% held out for final evaluation\n",
    "\n",
    "# K-fold settings (only used when DT_VALIDATION_METHOD = 'kfold')\n",
    "DT_CV = 3                         # number of cross-validation folds\n",
    "\n",
    "# Data subsampling for hyperparameter search\n",
    "# The full dataset can be millions of rows. Running cross-validated hyperopt\n",
    "# on all of it is slow. Subsampling uses a random fraction for the search,\n",
    "# then the final model is retrained on the FULL dataset with the best params.\n",
    "DT_SUBSAMPLE_FRACTION = 0.1    # fraction of data for search (0.1 = 10%)\n",
    "DT_SUBSAMPLE_MAX = 1_000_000   # hard cap on subsample size\n",
    "\n",
    "# ============================================================================\n",
    "# BUILD SEARCH SPACE FROM SETTINGS\n",
    "# ============================================================================\n",
    "DT_DEPTH_OPTIONS = list(range(DT_MIN_DEPTH, DT_MAX_DEPTH + 1, DT_DEPTH_STEP))\n",
    "DT_MSS_OPTIONS = list(range(DT_MIN_MSS, DT_MAX_MSS + 1, DT_MSS_STEP))\n",
    "DT_MSL_OPTIONS = list(range(DT_MIN_MSL, DT_MAX_MSL + 1, DT_MSL_STEP))\n",
    "DT_MSS_RANGE = (DT_MIN_MSS, DT_MAX_MSS)\n",
    "DT_MSL_RANGE = (DT_MIN_MSL, DT_MAX_MSL)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"DECISION TREE HYPERPARAMETER OPTIMIZATION\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Optimization:\")\n",
    "print(f\"  method:                {DT_OPTIMIZATION_METHOD}\")\n",
    "print(f\"Search space:\")\n",
    "print(f\"  max_depth:             {DT_MIN_DEPTH} to {DT_MAX_DEPTH} (step {DT_DEPTH_STEP}) -> {len(DT_DEPTH_OPTIONS)} choices\")\n",
    "print(f\"  min_samples_split:     {DT_MIN_MSS} to {DT_MAX_MSS} (step {DT_MSS_STEP}) -> {len(DT_MSS_OPTIONS)} choices\")\n",
    "print(f\"  min_samples_leaf:      {DT_MIN_MSL} to {DT_MAX_MSL} (step {DT_MSL_STEP}) -> {len(DT_MSL_OPTIONS)} choices\")\n",
    "print(f\"  min_impurity_decrease: {DT_MIN_IMPURITY_DECREASE} (fixed)\")\n",
    "if DT_OPTIMIZATION_METHOD == 'bayesian':\n",
    "    print(f\"  max_evals:             {DT_MAX_EVALS}\")\n",
    "print(f\"Validation:\")\n",
    "print(f\"  method:                {DT_VALIDATION_METHOD}\")\n",
    "if DT_VALIDATION_METHOD == 'holdout':\n",
    "    print(f\"  split:                 train={DT_TRAIN_FRACTION:.0%} / val={DT_VAL_FRACTION:.0%} / test={DT_TEST_FRACTION:.0%}\")\n",
    "else:\n",
    "    print(f\"  cv folds:              {DT_CV}\")\n",
    "print(f\"Subsampling:\")\n",
    "print(f\"  fraction:              {DT_SUBSAMPLE_FRACTION*100:.0f}% (max {DT_SUBSAMPLE_MAX:,})\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ============================================================================\n",
    "# RUN HYPERPARAMETER OPTIMIZATION\n",
    "# ============================================================================\n",
    "dt_optimizer = DecisionTreeEvaluator()\n",
    "\n",
    "opt_result_dt = dt_optimizer.optimize_hyperparameters(\n",
    "    df_tier,\n",
    "    method=DT_OPTIMIZATION_METHOD,\n",
    "    max_evals=DT_MAX_EVALS,\n",
    "    cv_folds=DT_CV,\n",
    "    verbose=True,\n",
    "    transformation_config=TRANSFORMATION_CONFIG,\n",
    "    max_depth_options=DT_DEPTH_OPTIONS,\n",
    "    min_samples_split_range=DT_MSS_RANGE,\n",
    "    min_samples_leaf_range=DT_MSL_RANGE,\n",
    "    min_impurity_decrease=DT_MIN_IMPURITY_DECREASE,\n",
    "    subsample_fraction=DT_SUBSAMPLE_FRACTION,\n",
    "    subsample_max_samples=DT_SUBSAMPLE_MAX,\n",
    "    # Validation strategy\n",
    "    validation_method=DT_VALIDATION_METHOD,\n",
    "    train_fraction=DT_TRAIN_FRACTION,\n",
    "    val_fraction=DT_VAL_FRACTION,\n",
    "    test_fraction=DT_TEST_FRACTION,\n",
    "    # Uncertainty-based sample filtering\n",
    "    use_uncertainty_weights=USE_UNCERTAINTY_WEIGHTS,\n",
    "    missing_uncertainty_handling=MISSING_UNCERTAINTY_HANDLING,\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# TRAIN FINAL MODEL WITH OPTIMAL HYPERPARAMETERS ON FULL DATA\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TRAINING FINAL MODEL WITH OPTIMAL HYPERPARAMETERS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nUncertainty Weighting:\")\n",
    "print(f\"  use_uncertainty_weights:      {USE_UNCERTAINTY_WEIGHTS}\")\n",
    "print(f\"  missing_uncertainty_handling: '{MISSING_UNCERTAINTY_HANDLING}'\")\n",
    "print()\n",
    "\n",
    "dt_model = DecisionTreeEvaluator(**opt_result_dt['best_params'])\n",
    "dt_metrics = dt_model.train(\n",
    "    df_tier,\n",
    "    transformation_config=TRANSFORMATION_CONFIG,\n",
    "    use_uncertainty_weights=USE_UNCERTAINTY_WEIGHTS,\n",
    "    missing_uncertainty_handling=MISSING_UNCERTAINTY_HANDLING,\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# PHASE-SPACE HOLDOUT EVALUATION (Decision Tree)\n",
    "# ============================================================================\n",
    "dt_holdout_metrics = None\n",
    "if df_holdout is not None and len(df_holdout) > 0:\n",
    "    dt_holdout_metrics = compute_holdout_metrics(\n",
    "        dt_model, df_holdout, dt_model.pipeline)\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"PHASE-SPACE HOLDOUT METRICS (Decision Tree)\")\n",
    "    print(\"=\" * 80)\n",
    "    for k, v in dt_holdout_metrics.items():\n",
    "        if isinstance(v, float):\n",
    "            print(f\"  {k:30s}: {v:.6f}\")\n",
    "        else:\n",
    "            print(f\"  {k:30s}: {v}\")\n",
    "    print(\"=\" * 80)\n",
    "else:\n",
    "    print(\"\\n[--] Holdout evaluation skipped (no holdout data)\")"
   ],
   "id": "cell-11"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree predictions\n",
    "\n",
    "The plots below overlay the Decision Tree's predictions on actual EXFOR\n",
    "data points for two evaluation isotopes.\n",
    "\n",
    "- **U-233 total XS** (data-rich): many training points are available for\n",
    "  this isotope/reaction.\n",
    "- **Cl-35 (n,p)** (data-sparse): the model relies on patterns learned from\n",
    "  other isotopes to fill gaps in energy coverage.\n"
   ],
   "id": "cell-12"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T21:45:39.157756Z",
     "iopub.status.busy": "2026-01-26T21:45:39.155688Z",
     "iopub.status.idle": "2026-01-26T21:45:48.995366Z",
     "shell.execute_reply": "2026-01-26T21:45:48.991588Z"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# VISUALIZATION: Decision Tree predictions on evaluation isotopes\n",
    "# ============================================================================\n",
    "# IsotopePlotter handles all data filtering, prediction generation, and\n",
    "# plotting in a single call.  Just specify Z, A, MT.\n",
    "\n",
    "from nucml_next.visualization import IsotopePlotter\n",
    "\n",
    "# Energy range for all plots\n",
    "E_MIN_PLOT = 1e-4   # 10^-4 eV\n",
    "E_MAX_PLOT = 1e7    # 10^7 eV\n",
    "\n",
    "df_plot = df_tier\n",
    "\n",
    "# ── Filter to z_score-assessed points (match explorer) ──────────────────────\n",
    "# The ThresholdExplorer only shows points with a valid z_score.\n",
    "# Points without z_score (groups too small for MAD computation) may include\n",
    "# un-assessed outliers.  Drop them so the scatter matches the explorer.\n",
    "if 'z_score' in dataset_full.df.columns:\n",
    "    _scored_idx = dataset_full.df.index[dataset_full.df['z_score'].notna()]\n",
    "    _n_before = len(df_plot)\n",
    "    df_plot = df_plot.loc[df_plot.index.isin(_scored_idx)]\n",
    "    _n_dropped = _n_before - len(df_plot)\n",
    "    if _n_dropped > 0:\n",
    "        print(f\"[z_score filter] Removed {_n_dropped:,} unscored points \"\n",
    "              f\"({_n_before:,} \\u2192 {len(df_plot):,})\")\n",
    "\n",
    "# ── Combine training + holdout for visualization ─────────────────────────────\n",
    "if df_holdout is not None and len(df_holdout) > 0:\n",
    "    df_plot_all = pd.concat([df_plot, df_holdout], ignore_index=True)\n",
    "    print(f\"[Holdout included] Combined {len(df_plot):,} training + \"\n",
    "          f\"{len(df_holdout):,} holdout = {len(df_plot_all):,} total for plotting\")\n",
    "else:\n",
    "    df_plot_all = df_plot\n",
    "\n",
    "# Create plotter (ENDF_DIR defined in cell 5)\n",
    "plotter_dt = IsotopePlotter(\n",
    "    training_df=df_plot_all,\n",
    "    models={'Decision Tree': dt_model},\n",
    "    energy_range=(E_MIN_PLOT, E_MAX_PLOT),\n",
    "    endf_dir=ENDF_DIR,\n",
    ")\n",
    "\n",
    "# U-233 Total XS (data-rich)\n",
    "plotter_dt.plot(Z=92, A=233, MT=1)\n",
    "\n",
    "# Cl-35 (n,p) (data-sparse)\n",
    "plotter_dt.plot(Z=17, A=35, MT=103)"
   ],
   "id": "cell-13"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How Decision Trees produce predictions\n",
    "\n",
    "A Decision Tree recursively splits on feature thresholds:\n",
    "\n",
    "```\n",
    "if Energy < 10.5:\n",
    "    if Energy < 5.2:\n",
    "        return 150.0   # constant within this leaf\n",
    "    else:\n",
    "        return 89.0    # discontinuous jump at boundary\n",
    "else:\n",
    "    return 45.0\n",
    "```\n",
    "\n",
    "Each leaf returns a single value, so the predicted cross-section curve is a\n",
    "step function regardless of how the tree is tuned. Compare this with the\n",
    "smooth Breit-Wigner form that describes resonance peaks in nuclear\n",
    "cross sections:\n",
    "\n",
    "$$\\sigma(E) = \\sigma_0 \\frac{\\Gamma}{(E - E_r)^2 + \\Gamma^2/4}$$\n",
    "\n",
    "---\n",
    "\n",
    "## Baseline 2 -- XGBoost\n",
    "\n",
    "XGBoost builds an ensemble of shallow decision trees via gradient boosting.\n",
    "Because many trees contribute to each prediction, the resulting curve is\n",
    "a sum of many step functions -- still piecewise constant, but with finer\n",
    "steps.\n",
    "\n",
    "The same Bayesian hyperparameter search strategy is applied here.\n"
   ],
   "id": "cell-14"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T21:45:49.019962Z",
     "iopub.status.busy": "2026-01-26T21:45:49.018865Z",
     "iopub.status.idle": "2026-01-26T21:53:51.719087Z",
     "shell.execute_reply": "2026-01-26T21:53:51.711598Z"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# HYPERPARAMETER OPTIMIZATION FOR XGBOOST\n",
    "# ============================================================================\n",
    "# Find good hyperparameters using Bayesian optimization (hyperopt TPE).\n",
    "# Consistent with the Decision Tree approach: min/max ranges, subsampling,\n",
    "# and final retrain on FULL data with the best parameters.\n",
    "\n",
    "# ============================================================================\n",
    "# USER CONFIGURATION: Hyperparameter Search Space\n",
    "# ============================================================================\n",
    "\n",
    "# n_estimators: Number of boosting rounds (trees in the ensemble)\n",
    "XGB_MIN_ESTIMATORS = 100\n",
    "XGB_MAX_ESTIMATORS = 300\n",
    "\n",
    "# max_depth: Maximum depth of each tree (shallower than single DT)\n",
    "XGB_MIN_DEPTH = 4\n",
    "XGB_MAX_DEPTH = 10\n",
    "\n",
    "# learning_rate (eta): Step size shrinkage to prevent overfitting\n",
    "XGB_LR_MIN = 0.01\n",
    "XGB_LR_MAX = 0.2\n",
    "\n",
    "# subsample: Fraction of training samples used per tree\n",
    "XGB_SUBSAMPLE_MIN = 0.7\n",
    "XGB_SUBSAMPLE_MAX_FRAC = 1.0\n",
    "\n",
    "# Bayesian search budget\n",
    "XGB_MAX_EVALS = 100         # number of hyperopt trials\n",
    "\n",
    "# Data subsampling for hyperparameter search\n",
    "XGB_SUBSAMPLE_FRACTION = 0.1    # 10% of data for search\n",
    "XGB_SUBSAMPLE_MAX = 1_000_000   # hard cap on subsample size\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"XGBOOST HYPERPARAMETER OPTIMIZATION\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Search space:\")\n",
    "print(f\"  n_estimators:    {XGB_MIN_ESTIMATORS} to {XGB_MAX_ESTIMATORS}\")\n",
    "print(f\"  max_depth:       {XGB_MIN_DEPTH} to {XGB_MAX_DEPTH}\")\n",
    "print(f\"  learning_rate:   {XGB_LR_MIN} to {XGB_LR_MAX}\")\n",
    "print(f\"  subsample:       {XGB_SUBSAMPLE_MIN} to {XGB_SUBSAMPLE_MAX_FRAC}\")\n",
    "print(f\"Optimization:\")\n",
    "print(f\"  method:          bayesian (hyperopt TPE)\")\n",
    "print(f\"  max_evals:       {XGB_MAX_EVALS}\")\n",
    "print(f\"Subsampling:\")\n",
    "print(f\"  fraction:        {XGB_SUBSAMPLE_FRACTION*100:.0f}% (max {XGB_SUBSAMPLE_MAX:,})\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ============================================================================\n",
    "# RUN HYPERPARAMETER OPTIMIZATION\n",
    "# ============================================================================\n",
    "xgb_optimizer = XGBoostEvaluator()\n",
    "\n",
    "opt_result_xgb = xgb_optimizer.optimize_hyperparameters(\n",
    "    df_tier,\n",
    "    max_evals=XGB_MAX_EVALS,\n",
    "    verbose=True,\n",
    "    transformation_config=TRANSFORMATION_CONFIG,\n",
    "    n_estimators_range=(XGB_MIN_ESTIMATORS, XGB_MAX_ESTIMATORS),\n",
    "    max_depth_range=(XGB_MIN_DEPTH, XGB_MAX_DEPTH),\n",
    "    learning_rate_range=(XGB_LR_MIN, XGB_LR_MAX),\n",
    "    subsample_range=(XGB_SUBSAMPLE_MIN, XGB_SUBSAMPLE_MAX_FRAC),\n",
    "    subsample_fraction=XGB_SUBSAMPLE_FRACTION,\n",
    "    subsample_max_samples=XGB_SUBSAMPLE_MAX,\n",
    "    # Uncertainty-based sample filtering\n",
    "    use_uncertainty_weights=USE_UNCERTAINTY_WEIGHTS,\n",
    "    missing_uncertainty_handling=MISSING_UNCERTAINTY_HANDLING,\n",
    ")\n",
    "\n",
    "best_params_xgb = opt_result_xgb['best_params']\n",
    "\n",
    "# ============================================================================\n",
    "# TRAIN FINAL MODEL WITH OPTIMAL HYPERPARAMETERS ON FULL DATA\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TRAINING FINAL MODEL WITH OPTIMAL HYPERPARAMETERS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nUncertainty Weighting:\")\n",
    "print(f\"  use_uncertainty_weights:      {USE_UNCERTAINTY_WEIGHTS}\")\n",
    "print(f\"  missing_uncertainty_handling: '{MISSING_UNCERTAINTY_HANDLING}'\")\n",
    "print()\n",
    "\n",
    "xgb_model = XGBoostEvaluator(**best_params_xgb)\n",
    "xgb_metrics = xgb_model.train(\n",
    "    df_tier,\n",
    "    transformation_config=TRANSFORMATION_CONFIG,\n",
    "    use_uncertainty_weights=USE_UNCERTAINTY_WEIGHTS,\n",
    "    missing_uncertainty_handling=MISSING_UNCERTAINTY_HANDLING,\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# PHASE-SPACE HOLDOUT EVALUATION (XGBoost)\n",
    "# ============================================================================\n",
    "xgb_holdout_metrics = None\n",
    "if df_holdout is not None and len(df_holdout) > 0:\n",
    "    xgb_holdout_metrics = compute_holdout_metrics(\n",
    "        xgb_model, df_holdout, xgb_model.pipeline)\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"PHASE-SPACE HOLDOUT METRICS (XGBoost)\")\n",
    "    print(\"=\" * 80)\n",
    "    for k, v in xgb_holdout_metrics.items():\n",
    "        if isinstance(v, float):\n",
    "            print(f\"  {k:30s}: {v:.6f}\")\n",
    "        else:\n",
    "            print(f\"  {k:30s}: {v}\")\n",
    "    print(\"=\" * 80)\n",
    "else:\n",
    "    print(\"\\n[--] Holdout evaluation skipped (no holdout data)\")"
   ],
   "id": "cell-15"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T21:53:51.758854Z",
     "iopub.status.busy": "2026-01-26T21:53:51.756731Z",
     "iopub.status.idle": "2026-01-26T21:53:54.113670Z",
     "shell.execute_reply": "2026-01-26T21:53:54.110641Z"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# XGBoost vs Decision Tree Comparison\n",
    "# ============================================================================\n",
    "# Both models on the same plot for direct visual comparison.\n",
    "\n",
    "from nucml_next.visualization import IsotopePlotter\n",
    "\n",
    "plotter_compare = IsotopePlotter(\n",
    "    training_df=df_plot_all,\n",
    "    models={'Decision Tree': dt_model, 'XGBoost': xgb_model},\n",
    "    energy_range=(E_MIN_PLOT, E_MAX_PLOT),\n",
    "    endf_dir=ENDF_DIR,\n",
    ")\n",
    "\n",
    "# U-233 Total XS — both models overlaid\n",
    "plotter_compare.plot(\n",
    "    Z=92, A=233, MT=1,\n",
    "    title='XGBoost vs Decision Tree\\nU-233 Total XS (Model trained on full EXFOR)',\n",
    ")"
   ],
   "id": "cell-16"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Baseline 3 -- Simple Neural Network\n",
    "\n",
    "A small feedforward neural network trained on the same features as the tree\n",
    "models.  Unlike trees, a neural network can produce smooth (continuous)\n",
    "predictions because it composes differentiable activation functions.\n",
    "\n",
    "This cell offers three loss functions to compare:\n",
    "\n",
    "| Loss | Formula | Use case |\n",
    "|------|---------|----------|\n",
    "| **MSE** | $\\frac{1}{N}\\sum(y_i - \\hat{y}_i)^2$ | Standard regression baseline |\n",
    "| **Chi-squared** | $\\frac{1}{N}\\sum\\frac{(y_i - \\hat{y}_i)^2}{\\sigma_i^2}$ | Weights by measurement precision |\n",
    "| **Physics-informed** | MSE + $\\lambda_\\text{smooth}\\cdot\\|\\nabla\\hat{\\sigma}\\|$ | Penalises unphysical oscillations |\n",
    "\n",
    "The network is deliberately small (2 hidden layers) so that training time is\n",
    "comparable to the tree baselines.  The goal is not state-of-the-art accuracy\n",
    "but rather to illustrate the difference in prediction character (smooth vs\n",
    "piecewise constant)."
   ],
   "metadata": {},
   "id": "cell-17"
  },
  {
   "cell_type": "code",
   "source": [
    "# ============================================================================\n",
    "# BASELINE 3: SIMPLE NEURAL NETWORK\n",
    "# ============================================================================\n",
    "# A small feedforward network comparable to the DT and XGB baselines.\n",
    "# Trains on the same transformed features and targets.\n",
    "#\n",
    "# LOSS FUNCTION OPTIONS:\n",
    "#   'mse'              — Standard mean squared error\n",
    "#   'chi_squared'      — Weighted MSE using inverse uncertainty (chi²/N)\n",
    "#   'physics_informed' — MSE + smoothness penalty on dσ/dE\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from nucml_next.data.transformations import TransformationPipeline\n",
    "\n",
    "# ============================================================================\n",
    "# USER CONFIGURATION\n",
    "# ============================================================================\n",
    "NN_LOSS_FUNCTION = 'mse'          # 'mse' | 'chi_squared' | 'physics_informed'\n",
    "NN_HIDDEN_SIZES = [128, 64]       # Hidden layer widths\n",
    "NN_EPOCHS = 80                    # Training epochs\n",
    "NN_BATCH_SIZE = 4096              # Mini-batch size\n",
    "NN_LEARNING_RATE = 1e-3           # Adam learning rate\n",
    "NN_SMOOTHNESS_WEIGHT = 0.01      # Lambda for physics-informed smoothness term\n",
    "NN_TEST_FRACTION = 0.15           # Held-out test fraction\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"NEURAL NETWORK BASELINE\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"  Loss function:   {NN_LOSS_FUNCTION}\")\n",
    "print(f\"  Hidden layers:   {NN_HIDDEN_SIZES}\")\n",
    "print(f\"  Epochs:          {NN_EPOCHS}\")\n",
    "print(f\"  Batch size:      {NN_BATCH_SIZE}\")\n",
    "print(f\"  Learning rate:   {NN_LEARNING_RATE}\")\n",
    "if NN_LOSS_FUNCTION == 'physics_informed':\n",
    "    print(f\"  Smoothness λ:    {NN_SMOOTHNESS_WEIGHT}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ============================================================================\n",
    "# PREPARE DATA (same pipeline as tree baselines)\n",
    "# ============================================================================\n",
    "exclude_columns = ['CrossSection', 'Uncertainty', 'Energy_Uncertainty', 'Entry', 'MT']\n",
    "numeric_cols = df_tier.select_dtypes(include=[np.number]).columns.tolist()\n",
    "nn_feature_columns = [col for col in numeric_cols if col not in exclude_columns]\n",
    "\n",
    "X_feat = df_tier[nn_feature_columns]\n",
    "y_raw = df_tier['CrossSection']\n",
    "energy_raw = df_tier['Energy']\n",
    "\n",
    "nn_pipeline = TransformationPipeline(config=TRANSFORMATION_CONFIG)\n",
    "nn_pipeline.fit(X_feat, y_raw, energy_raw, feature_columns=nn_feature_columns)\n",
    "\n",
    "X_t = nn_pipeline.transform(X_feat, energy_raw)\n",
    "y_t = nn_pipeline.transform_target(y_raw)\n",
    "\n",
    "X_np = X_t[nn_feature_columns].values.astype(np.float32)\n",
    "y_np = y_t.values.astype(np.float32).reshape(-1, 1)\n",
    "\n",
    "# Energy column (transformed) for physics-informed loss\n",
    "energy_col_idx = nn_feature_columns.index('Energy')\n",
    "\n",
    "# Uncertainty weights for chi-squared loss\n",
    "if NN_LOSS_FUNCTION == 'chi_squared' and 'Uncertainty' in df_tier.columns:\n",
    "    unc_raw = df_tier['Uncertainty'].values.astype(np.float32)\n",
    "    # Transform uncertainty to log-space: delta(log sigma) ≈ delta_sigma / sigma\n",
    "    xs_vals = df_tier['CrossSection'].values.astype(np.float32)\n",
    "    unc_log = np.where(\n",
    "        (np.isfinite(unc_raw)) & (unc_raw > 0) & (xs_vals > 0),\n",
    "        unc_raw / (xs_vals * np.log(10) + 1e-30),   # d(log10 x) = dx/(x ln10)\n",
    "        np.nan,\n",
    "    )\n",
    "else:\n",
    "    unc_log = np.full(len(y_np), np.nan, dtype=np.float32)\n",
    "\n",
    "# Drop invalid rows\n",
    "valid = np.isfinite(X_np).all(axis=1) & np.isfinite(y_np.ravel())\n",
    "if NN_LOSS_FUNCTION == 'chi_squared':\n",
    "    valid &= np.isfinite(unc_log) & (unc_log > 0)\n",
    "X_np, y_np, unc_log = X_np[valid], y_np[valid], unc_log[valid]\n",
    "print(f\"Valid samples: {valid.sum():,} / {len(valid):,}\")\n",
    "\n",
    "# Train/test split\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "idx_train, idx_test = tts(np.arange(len(X_np)), test_size=NN_TEST_FRACTION, random_state=42)\n",
    "\n",
    "X_train_t = torch.from_numpy(X_np[idx_train])\n",
    "y_train_t = torch.from_numpy(y_np[idx_train])\n",
    "X_test_t  = torch.from_numpy(X_np[idx_test])\n",
    "y_test_t  = torch.from_numpy(y_np[idx_test])\n",
    "unc_train_t = torch.from_numpy(unc_log[idx_train])\n",
    "\n",
    "train_ds = TensorDataset(X_train_t, y_train_t, unc_train_t)\n",
    "train_dl = DataLoader(train_ds, batch_size=NN_BATCH_SIZE, shuffle=True)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# ============================================================================\n",
    "# DEFINE NETWORK\n",
    "# ============================================================================\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self, n_features, hidden_sizes):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev = n_features\n",
    "        for h in hidden_sizes:\n",
    "            layers += [nn.Linear(prev, h), nn.ReLU(), nn.BatchNorm1d(h)]\n",
    "            prev = h\n",
    "        layers.append(nn.Linear(prev, 1))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "n_features = X_train_t.shape[1]\n",
    "model_nn = SimpleNet(n_features, NN_HIDDEN_SIZES).to(device)\n",
    "optimizer = torch.optim.Adam(model_nn.parameters(), lr=NN_LEARNING_RATE)\n",
    "print(f\"Parameters: {sum(p.numel() for p in model_nn.parameters()):,}\")\n",
    "\n",
    "# ============================================================================\n",
    "# LOSS FUNCTIONS\n",
    "# ============================================================================\n",
    "def mse_loss(pred, target, **kw):\n",
    "    return ((pred - target) ** 2).mean()\n",
    "\n",
    "def chi_squared_loss(pred, target, unc=None, **kw):\n",
    "    \"\"\"Chi-squared / N: weight each residual by 1/sigma^2.\"\"\"\n",
    "    if unc is None or not torch.isfinite(unc).all():\n",
    "        return mse_loss(pred, target)\n",
    "    var = (unc ** 2).clamp(min=1e-12)\n",
    "    return ((pred - target) ** 2 / var).mean()\n",
    "\n",
    "def physics_informed_loss(pred, target, energy=None, lam=0.01, **kw):\n",
    "    \"\"\"MSE + smoothness penalty on dσ/dE (penalises unphysical oscillations).\n",
    "\n",
    "    The smoothness term encourages the network to produce predictions that\n",
    "    vary smoothly with energy — a basic physics prior since real cross\n",
    "    sections are smooth functions of energy (even resonances have analytic\n",
    "    Breit-Wigner shapes rather than discontinuities).\n",
    "    \"\"\"\n",
    "    data_loss = ((pred - target) ** 2).mean()\n",
    "    if energy is None:\n",
    "        return data_loss\n",
    "    # Sort by energy so finite differences approximate the derivative\n",
    "    order = energy.argsort()\n",
    "    pred_sorted = pred[order].squeeze()\n",
    "    e_sorted = energy[order]\n",
    "    dE = (e_sorted[1:] - e_sorted[:-1]).clamp(min=1e-12)\n",
    "    dS = pred_sorted[1:] - pred_sorted[:-1]\n",
    "    smoothness = (dS / dE).abs().mean()\n",
    "    return data_loss + lam * smoothness\n",
    "\n",
    "loss_fn = {\n",
    "    'mse': mse_loss,\n",
    "    'chi_squared': chi_squared_loss,\n",
    "    'physics_informed': physics_informed_loss,\n",
    "}[NN_LOSS_FUNCTION]\n",
    "\n",
    "# ============================================================================\n",
    "# TRAINING LOOP\n",
    "# ============================================================================\n",
    "history = []\n",
    "for epoch in range(1, NN_EPOCHS + 1):\n",
    "    model_nn.train()\n",
    "    epoch_loss = 0.0\n",
    "    for xb, yb, ub in train_dl:\n",
    "        xb, yb, ub = xb.to(device), yb.to(device), ub.to(device)\n",
    "        pred = model_nn(xb)\n",
    "        kwargs = {}\n",
    "        if NN_LOSS_FUNCTION == 'chi_squared':\n",
    "            kwargs['unc'] = ub\n",
    "        elif NN_LOSS_FUNCTION == 'physics_informed':\n",
    "            kwargs['energy'] = xb[:, energy_col_idx]\n",
    "            kwargs['lam'] = NN_SMOOTHNESS_WEIGHT\n",
    "        loss = loss_fn(pred, yb, **kwargs)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item() * len(xb)\n",
    "    epoch_loss /= len(idx_train)\n",
    "    history.append(epoch_loss)\n",
    "    if epoch % 20 == 0 or epoch == 1:\n",
    "        print(f\"  Epoch {epoch:3d}/{NN_EPOCHS}  loss={epoch_loss:.6f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# EVALUATE\n",
    "# ============================================================================\n",
    "model_nn.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_test = model_nn(X_test_t.to(device)).cpu().numpy().ravel()\n",
    "\n",
    "# Inverse-transform predictions and targets back to barns\n",
    "y_pred_barns = nn_pipeline.inverse_transform_target(pd.Series(y_pred_test)).values\n",
    "y_true_barns = nn_pipeline.inverse_transform_target(pd.Series(y_np[idx_test].ravel())).values\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "nn_mse  = mean_squared_error(y_true_barns, y_pred_barns)\n",
    "nn_mae  = mean_absolute_error(y_true_barns, y_pred_barns)\n",
    "nn_r2   = r2_score(y_true_barns, y_pred_barns)\n",
    "\n",
    "print(f\"\\nNeural Network ({NN_LOSS_FUNCTION}) — Test Metrics (barns):\")\n",
    "print(f\"  MSE:  {nn_mse:.4e}\")\n",
    "print(f\"  MAE:  {nn_mae:.4e}\")\n",
    "print(f\"  R²:   {nn_r2:.4f}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ============================================================================\n",
    "# WRAP IN A PREDICT-COMPATIBLE OBJECT FOR IsotopePlotter\n",
    "# ============================================================================\n",
    "class _NNPredictor:\n",
    "    \"\"\"Thin wrapper so IsotopePlotter can call nn_model.predict(df).\"\"\"\n",
    "    def __init__(self, net, pipeline, feature_columns, device):\n",
    "        self.net = net\n",
    "        self.pipeline = pipeline\n",
    "        self.feature_columns = feature_columns\n",
    "        self._device = device\n",
    "\n",
    "    def predict(self, df, energy_column='Energy'):\n",
    "        X = df[self.feature_columns]\n",
    "        energy = df[energy_column] if energy_column in df.columns else None\n",
    "        Xt = self.pipeline.transform(X, energy)\n",
    "        arr = Xt[self.feature_columns].values.astype(np.float32)\n",
    "        arr = np.nan_to_num(arr, nan=0.0, posinf=1e10, neginf=-1e10)\n",
    "        self.net.eval()\n",
    "        with torch.no_grad():\n",
    "            pred_t = self.net(torch.from_numpy(arr).to(self._device)).cpu().numpy().ravel()\n",
    "        return self.pipeline.inverse_transform_target(pd.Series(pred_t)).values\n",
    "\n",
    "nn_model = _NNPredictor(model_nn, nn_pipeline, nn_feature_columns, device)\n",
    "print(\"Neural network wrapped as nn_model (has .predict() for IsotopePlotter)\")"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "id": "cell-18"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## All Models + ENDF/B Comparison\n",
    "\n",
    "The plot below overlays all three baseline models (Decision Tree, XGBoost,\n",
    "Neural Network) together with the ENDF/B-VIII.0 evaluated data and the raw\n",
    "EXFOR experimental scatter.  This provides a single visual comparison of:\n",
    "\n",
    "- **EXFOR scatter** -- experimental measurements with their scatter\n",
    "- **ENDF/B-VIII.0** -- the authoritative evaluated library\n",
    "- **Decision Tree** -- piecewise constant (staircase)\n",
    "- **XGBoost** -- smoother piecewise constant (finer steps)\n",
    "- **Neural Network** -- smooth continuous predictions"
   ],
   "metadata": {},
   "id": "cell-19"
  },
  {
   "cell_type": "code",
   "source": [
    "# ============================================================================\n",
    "# ALL MODELS + ENDF/B + EXFOR: COMBINED COMPARISON\n",
    "# ============================================================================\n",
    "# Plot all three baselines alongside ENDF/B-VIII.0 and EXFOR scatter\n",
    "# for both evaluation isotopes.\n",
    "\n",
    "from nucml_next.visualization import IsotopePlotter\n",
    "\n",
    "plotter_all = IsotopePlotter(\n",
    "    training_df=df_plot_all,\n",
    "    models={\n",
    "        'Decision Tree': dt_model,\n",
    "        'XGBoost': xgb_model,\n",
    "        'Neural Net': nn_model,\n",
    "    },\n",
    "    energy_range=(E_MIN_PLOT, E_MAX_PLOT),\n",
    "    endf_dir=ENDF_DIR,\n",
    ")\n",
    "\n",
    "# ── U-233 Total XS (data-rich) ──────────────────────────────────────────────\n",
    "plotter_all.plot(\n",
    "    Z=92, A=233, MT=1,\n",
    "    show_endf=True,\n",
    "    title='All Baselines vs ENDF/B\\nU-233 Total XS',\n",
    ")\n",
    "\n",
    "# ── Cl-35 (n,p) (data-sparse) ───────────────────────────────────────────────\n",
    "plotter_all.plot(\n",
    "    Z=17, A=35, MT=103,\n",
    "    show_endf=True,\n",
    "    title='All Baselines vs ENDF/B\\nCl-35 (n,p)',\n",
    ")"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "id": "cell-20"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Decision Tree and XGBoost\n",
    "\n",
    "The comparison plot shows both models on U-233 total cross-section data.\n",
    "You may observe that:\n",
    "\n",
    "- XGBoost produces a smoother curve than the single Decision Tree because\n",
    "  it averages hundreds of weak learners.\n",
    "- Both models are piecewise constant by construction -- the underlying\n",
    "  architecture does not enforce continuity or smoothness.\n",
    "\n",
    "---\n",
    "\n",
    "## Feature importance\n",
    "\n",
    "XGBoost provides per-feature importance scores (gain-based). The bar chart\n",
    "below shows which input features the model relies on most heavily when\n",
    "making splits.\n"
   ],
   "id": "cell-21"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T21:53:54.124896Z",
     "iopub.status.busy": "2026-01-26T21:53:54.124306Z",
     "iopub.status.idle": "2026-01-26T21:53:54.598201Z",
     "shell.execute_reply": "2026-01-26T21:53:54.595351Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 Most Important Features:\n",
      "     Feature    Importance\n",
      "12         Z  31673.291016\n",
      "14         A  25156.460938\n",
      "15  S_1n_MeV  24204.935547\n",
      "16    Energy  21177.593750\n",
      "1      out_g  18813.681641\n"
     ]
    }
   ],
   "source": [
    "# Get feature importance\n",
    "importance = xgb_model.get_feature_importance()\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.barh(importance['Feature'], importance['Importance'])\n",
    "ax.set_xlabel('Importance (Gain)', fontsize=12, fontweight='bold')\n",
    "ax.set_title('XGBoost Feature Importance (Tier-Based Features)', fontsize=14, fontweight='bold')\n",
    "ax.invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 5 Most Important Features:\")\n",
    "print(importance.head())"
   ],
   "id": "cell-22"
  },
  {
   "cell_type": "code",
   "source": [
    "# ============================================================================\n",
    "# SAVE EXPERIMENTS (Optional)\n",
    "# ============================================================================\n",
    "# After reviewing the training results above, decide whether to save:\n",
    "#   - Trained model files (.joblib)\n",
    "#   - Scaler/pipeline artifacts\n",
    "#   - Plots for each evaluation isotope\n",
    "#\n",
    "# Set SAVE_EXPERIMENTS = True to persist everything to disk.\n",
    "# Experiments are saved to: experiments/<model>_<timestamp>/\n",
    "\n",
    "SAVE_EXPERIMENTS = False  # Set to True to save models, scalers, and plots\n",
    "\n",
    "if SAVE_EXPERIMENTS:\n",
    "    from nucml_next.experiment import ExperimentManager\n",
    "    \n",
    "    exp_mgr = ExperimentManager()\n",
    "    \n",
    "    # ── Save Decision Tree experiment ────────────────────────────────────────\n",
    "    print(\"=\" * 80)\n",
    "    print(\"SAVING DECISION TREE EXPERIMENT\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    dt_exp_dir = exp_mgr.save_experiment(\n",
    "        model=dt_model,\n",
    "        model_type='decision_tree',\n",
    "        selection=training_selection,\n",
    "        holdout_config=HOLDOUT_CONFIG if HOLDOUT_CONFIG.rules else None,\n",
    "        holdout_metrics=dt_holdout_metrics,\n",
    "        extra_metadata={\n",
    "            'metrics': dt_metrics,\n",
    "            'hyperopt_result': opt_result_dt,\n",
    "            'transformation_config': str(TRANSFORMATION_CONFIG),\n",
    "        },\n",
    "    )\n",
    "    print(f\"[OK] Decision Tree saved to: {dt_exp_dir}\")\n",
    "    \n",
    "    # Save Decision Tree plots\n",
    "    plotter_dt_save = IsotopePlotter(\n",
    "        training_df=df_plot_all,\n",
    "        models={'Decision Tree': dt_model},\n",
    "        energy_range=(E_MIN_PLOT, E_MAX_PLOT),\n",
    "        experiment_dir=dt_exp_dir,\n",
    "    )\n",
    "    plotter_dt_save.plot(Z=92, A=233, MT=1)\n",
    "    plotter_dt_save.plot(Z=17, A=35, MT=103)\n",
    "    print(f\"[OK] Decision Tree plots saved\")\n",
    "    \n",
    "    # ── Save XGBoost experiment ──────────────────────────────────────────────\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"SAVING XGBOOST EXPERIMENT\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    xgb_exp_dir = exp_mgr.save_experiment(\n",
    "        model=xgb_model,\n",
    "        model_type='xgboost',\n",
    "        selection=training_selection,\n",
    "        holdout_config=HOLDOUT_CONFIG if HOLDOUT_CONFIG.rules else None,\n",
    "        holdout_metrics=xgb_holdout_metrics,\n",
    "        extra_metadata={\n",
    "            'metrics': xgb_metrics,\n",
    "            'hyperopt_result': {'best_params': best_params_xgb},\n",
    "            'transformation_config': str(TRANSFORMATION_CONFIG),\n",
    "        },\n",
    "    )\n",
    "    print(f\"[OK] XGBoost saved to: {xgb_exp_dir}\")\n",
    "    \n",
    "    # Save XGBoost plots\n",
    "    plotter_xgb_save = IsotopePlotter(\n",
    "        training_df=df_plot_all,\n",
    "        models={'XGBoost': xgb_model},\n",
    "        energy_range=(E_MIN_PLOT, E_MAX_PLOT),\n",
    "        experiment_dir=xgb_exp_dir,\n",
    "    )\n",
    "    plotter_xgb_save.plot(Z=92, A=233, MT=1)\n",
    "    plotter_xgb_save.plot(Z=17, A=35, MT=103)\n",
    "    print(f\"[OK] XGBoost plots saved\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ALL EXPERIMENTS SAVED SUCCESSFULLY\")\n",
    "    print(\"=\" * 80)\n",
    "else:\n",
    "    print(\"SAVE_EXPERIMENTS = False\")\n",
    "    print(\"Set SAVE_EXPERIMENTS = True above and re-run this cell to save models and plots.\")"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "id": "cell-23"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Conda base)",
   "language": "python",
   "name": "nucml-base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}